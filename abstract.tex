% \chapter*{ABSTRACT}
% \phantomsection
% \addcontentsline{toc}{chapter}{ABSTRACT} % This is to include this section in the Table of Contents
\begin{center}
{\Large \mytitle}

\vspace{2cm}

{\Large\spacedallcaps{ABSTRACT}}
\end{center}
% \vspace{1cm}

State-of-the-art neural language models are capable of generating incredibly fluent English text.
This success provides opportunities for novel forms of interaction, where human writers work collaboratively with a natural-language generation system toward a set of goals.
However, it also poses several challenges.
Evaluating and comparing the skill of different open-ended text generation systems is challenging, and generated text can have negative societal impact if it proliferates and people are not able to detect it.
In this dissertation, I introduce a detection-based evaluation task that can be used to investigate the tradeoff between generating high-quality and generating lexically diverse text.
I also show how large neural language models' capability of memorizing large swaths of their training data complicates our ability to evaluate their skill at generating high-quality \textit{novel} text.

Despite these challenges, I show how neural language models can be successfully employed to build tools for creative wetiers. \TODO{finish}
