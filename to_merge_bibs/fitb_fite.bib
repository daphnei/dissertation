@inproceedings{ippolito2019unsupervised,
  title={Unsupervised hierarchical story infilling},
  author={Ippolito, Daphne and Grangier, David and Callison-Burch, Chris and Eck, Douglas},
  booktitle={Proceedings of the First Workshop on Narrative Understanding},
  pages={37--43},
  year={2019}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@article{roemmele2021inspiration,
  title={Inspiration through Observation: Demonstrating the Influence of Automatically Generated Text on Creative Writing},
  author={Roemmele, Melissa},
  booktitle={Proceedings of the 12th International Conference on Computational Creativity},
  pages={52--461},
  year={2021},
  url={https://computationalcreativity.net/iccc21/wp-content/uploads/2021/09/ICCC_2021_paper_32.pdf}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from Language Models},
  author={Laura Weidinger and John Mellor and Maribeth Rauh and Conor Griffin and Jonathan Uesato and Po-Sen Huang and Myra Cheng and Mia Glaese and Borja Balle and Atoosa Kasirzadeh and Zac Kenton and Sasha Brown and Will Hawkins and Tom Stepleton and Courtney Biles and Abeba Birhane and Julia Haas and Laura Rimell and Lisa Anne Hendricks and William Isaac and Sean Legassick and Geoffrey Irving and Iason Gabriel},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}


@software{gpt-neo,
  author       = {Black, Sid and
                  Gao, Leo and
                  Wang, Phil and
                  Leahy, Connor and
                  Biderman, Stella},
  title        = {{GPT-Neo: Large Scale Autoregressive Language 
                   Modeling with Mesh-Tensorflow}},
  month        = mar,
  year         = 2021,
  note         = {{If you use this software, please cite it using 
                   these metadata.}},
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.5297715},
  url          = {https://doi.org/10.5281/zenodo.5297715}
}


@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{reif2021recipe,
  title={A recipe for arbitrary text style transfer with large language models},
  author={Reif, Emily and Ippolito, Daphne and Yuan, Ann and Coenen, Andy and Callison-Burch, Chris and Wei, Jason},
  journal={arXiv preprint arXiv:2109.03910},
  year={2021}
}

@article{joshi2020spanbert,
  title={SpanBERT: Improving Pre-training by Representing and Predicting Spans},
  author={Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S and Zettlemoyer, Luke and Levy, Omer},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={64--77},
  year={2020}
}

@article{zhu2019text,
  title={Text infilling},
  author={Zhu, Wanrong and Hu, Zhiting and Xing, Eric},
  journal={arXiv preprint arXiv:1901.00158},
  year={2019}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@inproceedings{lin2020commongen,
  title={CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning},
  author={Lin, Bill Yuchen and Zhou, Wangchunshu and Shen, Ming and Zhou, Pei and Bhagavatula, Chandra and Choi, Yejin and Ren, Xiang},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  pages={1823--1840},
  year={2020}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{fan2018hierarchical,
  title={Hierarchical neural story generation},
  author={Fan, Angela and Lewis, Mike and Dauphin, Yann},
  journal={arXiv preprint arXiv:1805.04833},
  year={2018}
}

@article{wu2018smart,
  title={Smart compose: Using neural networks to help write emails},
  author={Wu, Yonghui},
  journal={Google AI Blog},
  year={2018}
}

@article{roberts2020exploring,
  title={Exploring Transfer Learning with T5: The Text-To-Text Transfer Transformer},
  author={Roberts, A and Raffel, C},
  journal={Google AI Blog},
  year={2020},
  url={https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html}
}

@article{wordcraft,
  title={Wordcraft: a Human-AI Collaborative Editor for Story Writing},
  author={Coenen, Andy and Davis, Luke and Ippolito, Daphne and Yuan, Ann and Reif, Emily},
  booktitle={Proceedings of the First Workshop on Bridging Human–Computer Interaction and Natural Language Processing},
  year={2021}
}

@inproceedings{buschek2021impact,
  title={The impact of multiple parallel phrase suggestions on email input and composition behaviour of native and non-native english writers},
  author={Buschek, Daniel and Z{\"u}rn, Martin and Eiband, Malin},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2021}
}

@inproceedings{donahue2020enabling,
  title={Enabling Language Models to Fill in the Blanks},
  author={Donahue, Chris and Lee, Mina and Liang, Percy},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2492--2501},
  year={2020}
}

@inproceedings{mori2020finding,
  title={Finding and Generating a Missing Part for Story Completion},
  author={Mori, Yusuke and Yamane, Hiroaki and Mukuta, Yusuke and Harada, Tatsuya},
  booktitle={Proceedings of the The 4th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
  pages={156--166},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{akoury2020storium,
  title={STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation},
  author={Akoury, Nader and Wang, Shufan and Whiting, Josh and Hood, Stephen and Peng, Nanyun and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2010.01717},
  year={2020}
}

@inproceedings{mostafazadeh2016corpus,
    title = "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories",
    author = "Mostafazadeh, Nasrin  and
      Chambers, Nathanael  and
      He, Xiaodong  and
      Parikh, Devi  and
      Batra, Dhruv  and
      Vanderwende, Lucy  and
      Kohli, Pushmeet  and
      Allen, James",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N16-1098",
    doi = "10.18653/v1/N16-1098",
    pages = "839--849",
}

@inproceedings{huang2020inset,
  title={INSET: Sentence Infilling with INter-SEntential Transformer},
  author={Huang, Yichen and Zhang, Yizhe and Elachqar, Oussama and Cheng, Yu},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2502--2515},
  year={2020}
}

@article{mao2019improving,
  title={Improving neural story generation by targeted common sense grounding},
  author={Mao, Huanru Henry and Majumder, Bodhisattwa Prasad and McAuley, Julian and Cottrell, Garrison W},
  journal={arXiv preprint arXiv:1908.09451},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}


@article{dodge2021documenting,
  title={Documenting the English Colossal Clean Crawled Corpus},
  author={Dodge, Jesse and Sap, Maarten and Marasovic, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Gardner, Matt},
  journal={arXiv preprint arXiv:2104.08758},
  year={2021}
}

@article{taylor1953cloze,
  title={“Cloze procedure”: A new tool for measuring readability},
  author={Taylor, Wilson L},
  journal={Journalism Bulletin},
  volume={30},
  number={4},
  pages={415--433},
  year={1953},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{goldfarb2020content,
  title={Content planning for neural story generation with aristotelian rescoring},
  author={Goldfarb-Tarrant, Seraphina and Chakrabarty, Tuhin and Weischedel, Ralph and Peng, Nanyun},
  journal={arXiv preprint arXiv:2009.09870},
  year={2020}
}

@article{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Tony Z and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  journal={arXiv preprint arXiv:2102.09690},
  year={2021}
}

@misc{gpt3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@software{spacy,
  author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
  title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
  year = 2020,
  publisher = {Zenodo},
  doi = {10.5281/zenodo.1212303},
  url = {https://doi.org/10.5281/zenodo.1212303}
}

@article{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}