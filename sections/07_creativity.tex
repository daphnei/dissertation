\chapter{Enabling Applications in Creative Writing}
\label{chap:creativity}
One application in which NLG has considerable potential is in the development of tools for creative writing.
AI-assisted creative writing is an attractive testbed for NLG systems because ideation tools are already part of writers' arsenal, and mistakes like hallucinating false facts are less problematic in fiction than in domains like automatic news summarization, where faithfulness to the real world is crucial.
In addition, science fiction writers have been grappling with concepts of human-like machines and artificial intelligence for at least as long as computer scientists have, so it stands to reason they may be early adopters of AI-powered creative writing tools.

In this chapter, I describe work I have done toward bridging the gap between what most language models do by default (predict a continuation for a prompt) and the operations writers actually actually want to use to assist in the writing process.
% First, I will describe efforts to capture longer-term coherence by building a language model that operates over sentences rather than other sub-words.
First, I will show how existing neural networks can be modified to support fill-in-the-blank style tasks in addition to the more common paradigm of continuation.
Filling in the blank is a common functionality requested by writers.
Second, I will present a method for performing sentence style transfer--altering the style of an input to any arbitrary target of styles, such as rewriting text to be more Shakespearean, metaphorical, or melodramatic.
My method accomplishes this without any exemplars of the style transfer task or task-specific model training.
Third, to test out how these and other NLG-based tools can be used in practice, I present Wordcraft, a word processor augmented with a variety of ``smart'' writing controls and suggestion tools.
I describe how a single large language model is used to support all of the ``smart'' functions in Wordcraft, and I examine Wordcraft's strengths and limitations through user studies conducted with both amateur and professional writers.

% Artificial intelligence systems which can write stories have been a goal of researchers since the early days of computing.
% However, much of the early work in this area was focused on building systems which could produce an entire story from scratch given an initial set of constraints.
% Rather than focusing on developing NLG systems which produce entire stories, my research in this area focuses on enabling better human-AI collaboration.


\section{Supporting Arbitrary Style Transfer}
\label{section:style_transfer}

Text style transfer is the task of rewriting text to incorporate additional or alternative stylistic elements while preserving the overall semantics and structure.
% Although style transfer has garnered increased interest due to the success of deep learning, these approaches usually require a substantial amount of labeled training examples, either as parallel text data \citep{zhu-etal-2010-monolingual,rao-tetreault-2018-dear} or non-parallel text data of a single style. \citep{li-etal-2018-delete,jin-etal-2019-imat, liu2020revision,style-transfer-as-paraphrase-2020}. 
Early approaches to style transfer required \textit{parallel} text data \citep{zhu-etal-2010-monolingual,rao-tetreault-2018-dear}, where every input in the source style has a corresponding output in the target style.
Because the availability of such data is limited, however, there has been a shift toward approaches which instead rely on \textit{non-parallel} monostyle data \cite{li-etal-2018-delete,jin-etal-2019-imat, liu2020revision,style-transfer-as-paraphrase-2020}.
% % (no mapping between source and target style sentences)
Most recently, \textit{label-free} methods have taken advantage of the natural manifold of language (i.e. the idea that sentences that are nearby to each other in a text passage are also similar stylistically) to train style transfer models that require only a few exemplars in the target style for inference \citep{DBLP:journals/corr/abs-1905-11975, DBLP:journals/corr/abs-2010-03802}.
This is true even for approaches which claim to be label-free \citep{DBLP:journals/corr/abs-1905-11975,DBLP:journals/corr/abs-2010-03802}.
Hence, there is a clear need for new methods that both reduce the training data requirements and expand the scope of styles supported \citep{DBLP:journals/corr/abs-2011-00416,DBLP:journals/corr/abs-2010-12742}.

\begin{figure}[tbp]
    \centering
     \includegraphics[width=0.5\linewidth]{figures/style-transfer-prompt.pdf}
  \caption{Zero-shot, few-shot, and augmented zero-shot prompts for style transfer. The boldface text is the zero-shot prompt, and the plain text is the additional priming sequence. The full prompts are shown in Table \ref{tab:fullprompt}.}
  \label{prompts}
\end{figure}


In this section, we present \textit{augmented zero-shot learning}, a prompting method that allows large language models to perform text style transfer to arbitrary styles, without any exemplars in the target style.
Our method builds on prior work showing that sufficiently large LMs such as GPT-3 can perform various tasks ranging from classification to translation, simply by choosing a clever prompt to prepend to the input text for which the model is asked to continue \citep{DBLP:journals/corr/abs-2005-14165,branwen2020gpt}. 
Although large LMs are trained only for continuation, recent work has shown that they can perform a variety of NLP tasks by expressing the task as a prompt that encourages the model to output the desired answer as the continuation \citep{liu2021pre,puri2019zero,weller-etal-2020-learning,DBLP:journals/corr/abs-2005-14165,schick-schutze-2021-just}. 
The simplest approach, \textbf{zero-shot prompting}, directly uses natural language to ask the large LM to perform a task, as shown in Figure \ref{prompts}a.
Zero-shot learning, however, can be prone to failure modes such as not returning well-formatted or logical generations (see $\S$\ref{section:limitations}).
 % However, zero-shot prompts are prone to failure modes such as not returning a well formatted or logical answer.
This problem can often be overcome by prepending exemplars to the prompt that demonstrate what successful completions may look like.
This approach, called \textbf{few-shot prompting}, has been shown to achieve higher performance, but requires exemplars for the exact task that we want the model to perform (Figure \ref{prompts}b).

To remove the need for these labeled exemplars for each style transfer task, we propose \textit{augmented zero-shot learning}, a method for performing multi-task style transfer using a single set of exemplars.
Instead of prompting the model with exemplars specific to the exact style transfer task we wish to perform, we prompt the model with examples of a variety of sentence rewriting operations, as shown in Figure \ref{prompts}c. 
This intuition is inspired by \citet{reynolds2021prompt}'s observation that successful prompts constrain the behavior of the large LM away from failure modes---in our case, we aim to preserve the flexibility of a zero shot prompt while encouraging the model to produce outputs of a specific template.
We keep the the format of the exemplars constant and insert the desired sentence transformation into the same format.
In this way, the augmented zero-shot formulation supports arbitrary sentence rewriting tasks without the need to write any task-specific exemplars.
Thus, it works for a wide range of styles, including modifying the text to ``\textit{be more melodramatic,}'' ``\textit{insert a metaphor,}'' or ``\textit{include the word balloon.}''

Augmented zero-shot learning is simple and facilitates the application of style transfer to a wider range of styles than existing work.
We also foresee that our strategy of prompting an LLM with non-task specific examples will prove useful for other tasks besides style transfer.

\subsection{Experimental Setup}

\input{tables/nonstandard_style_transfer_examples}
\subsubsection{Style Transfer Tasks}
% \label{section:tasks}
% We evaluate augmented zero-shot prompting on a number of text style transfer tasks.
We considered six style transfer tasks that we deemed non-standard, listed in Table \ref{tab:style-transfer-examples}.
These styles were chosen to be representative of most frequent style adjustments made by users of Wordcraft in the user study described in Chapter \ref{section:wordcraft}.
As source sentences, we used 50 sentences randomly drawn from the Reddit Writing Prompts validation set \citep{fan2018hierarchical}, excluding those that already clearly exhibited one of the styles or were ungrammatical/incoherent.
We used human evaluation for these styles, since not all styles have readily available classifiers.
% For input sentences, we draw a random set of 50 sentences\footnote{We only evaluate 50 sentences because style transfer for arbitrary styles can only be evaluated manually, and we have many styles and models (totaling 7200 ratings.)} from short stores in the Reddit Writing Prompts validation set \citep{fan2018hierarchical}, excluding sentences that were incoherent or clearly exhibited one of the styles already. 

We also evaluated our method on two standard style transfer tasks: sentiment and formality.
We used the Yelp polarity dataset \citep{zhangCharacterlevelConvolutionalNetworks2015} for sentiment and Grammarly's Yahoo Answers Formality Corpus (GYAFC) dataset for formality \citep{rao-tetreault-2018-dear}.\footnote{Hosted by \citet{DBLP:conf/ijcai/LuoLZYCSS19}.}
These datasets allowed us to evaluate performance of augmented zero-shot learning in the context of prior supervised methods which have been used on these tasks.

\subsubsection{Model}
\label{subsection:lambda_description}
Augmented zero-shot learning requires a large language model.
We primarily use LaMDA, a left-to-right decoder-only transformer language model \citep{DBLP:journals/corr/VaswaniSPUJGKP17} with a non-embedding parameter count of 137B \citep{thoppilan2022lamda}. 
The pre-trained LaMDA model, which we refer to as \textit{LLM}, was trained on a corpus comprising 1.95B public web documents, including forum and dialog data and Wikipedia.
The dataset was tokenized into 2.49T BPE tokens with a SentencePiece vocabulary size of 32K \citep{DBLP:journals/corr/abs-1808-06226}.
We also used \textit{LLM-Dialog}, the final LaMDA model which was finetuned on a curated, high-quality subset of data identified to be in a conversational format.
Decoding was done with top-$k$=40.
To show that the success of augmented zero-shot learning was not restricted to these two large LMs, we also performed experiments with GPT-3 (Table \ref{tab:candidate_select}).
For GPT-3, decoding was done with nucleus sampling using $p$=0.6 \citep{holtzman2019curious}.

The full prompts used for \textit{LLM} and GPT-3 are shown in Figure \ref{tab:fullprompt}.
For \textit{LLM-Dialog}, the prompt was instead formulated as a conversation between one agent who is requesting rewrites and another who is performing the rewrites.

% \subsection{Evaluation}
% We evaluate the quality of our style transfers on three main axes.

% \begin{enumerate}[nolistsep]
%     \item \textbf{Transfer strength} is the amount that the output actually matches the desired target style. 
%     \item \textbf{Semantic preservation} is the similarity between the input and output texts: that is, the amount that the output text's underlying meaning and structure matches that of the input. This can be difficult to measure, as the style may change the attributes by definition. For example, if the original text is ``this restaurant is terrible'' and the style is ``have a more positive sentiment'', then the underlying meaning of the sentence will necessarily change.
%     \item \textbf{Fluency} is a measure of whether the text's coherence, i.e., whether it could have been written by a proficient English speaker.
% \end{enumerate}

% We evaluate with human raters to compare our method against baselines and prior methods. Additionally, we use automatic evaluation for the task of sentiment transfer to compare across a larger number of prior approaches and variations of our augmented zero-shot recipe.
% % As \citet{DBLP:journals/corr/abs-2010-12742} discuss, automatic evaluation for style transfer is a difficult problem since the domain is so subjective, and metrics calculated automatically do not always match human baselines.
% % Despite these caveats, automatic evaluation is ubiquitous in prior work.

% The outputs used for human evaluation were generated using augmented zero shot learning on LLM-dialog, with no candidate selection.
% For each input sentence and target style, raters were shown several possible outputs and asked to rate each (\textit{input}, \textit{style}, \textit{output}) tuple along the three axes of transfer strength, semantic preservation, and fluency.
% Each question was assigned to three different raters.
% Screenshots of the rater UI are shown in figure \ref{fig:rater_ui} in the Appendix. 

% For automatic evaluation, we evaluate transfer strength with the built-in sentiment classification model from HuggingFace \citep{wolf-etal-2020-transformers}, semantic preservation measured with BLEU \citep{papineni2002bleu}, and fluency (measured by perplexity with according to GPT-2, 117M) following \citet{DBLP:journals/corr/abs-2011-00416, DBLP:journals/corr/abs-2010-12742}.


\subsection{Results}
\paragraph{Non-Standard Styles}
For our six non-standard styles, we asked six professional raters to assess  <input sentence, target style, output sentence> tuples. These raters are fluent in English, live in India, and work full time labeling and evaluating data. To decrease inter-rater discrepancy and ensure that our instructions were clear, we had an initial calibration session where they test-rated a small portion of the data (around 10 datapoints which were then omitted from the results) and asked us any clarifying questions. For each style, we compared outputs from our method plus the three baselines for 50 sentences.

\begin{figure}[tbp]
  \centering
  \fbox{\includegraphics[width=0.8\linewidth]{figures/rater_ui.png}}
  \caption{The rating UI used for human evaluation. The user may be shown a number of blue squares at once with the same original text and different outputs.}
  \label{fig:rater_ui}
\end{figure} 

Each tuple was scored by three raters (3,600 ratings total) on the following three axes which are standard to textual style transfer \citep{DBLP:journals/corr/abs-1904-02295}:

\begin{enumerate}
\item \textbf{transfer strength}: the amount that the output actually matches the target style
\item \textbf{semantic preservation}: whether the underlying meaning of the output text, aside from style, matches that of the input and
\item \textbf{fluency}: whether the text is coherent and could have been written by a proficient English speaker
\end{enumerate}

Following \citet{sakaguchi-van-durme-2018-efficient}, transfer strength and semantic preservation were rated on a scale from 1--100. A screenshot of the evaluation UI is shown in Figure \ref{fig:rater_ui}.
We used \textit{dialog-LLM}, and compared it with three other methods:

\begin{enumerate}
\item \textbf{zero-shot}: a baseline where no exemplars were provided
\item \textbf{paraphrase}: our normal augmented zero shot prompt, but with the target style of \textit{``paraphrased''}, as a control 
\item \textbf{human}: groundtruth transformations written by my and my collaborators
\end{enumerate}

Figure \ref{human_eval_other_styles} shows these results. %, and all raw outputs can be found at \url{https://bit.ly/3fLDuci}.
We found that the outputs of our method were rated almost as highly as the human-written groundtruth for all three evaluations. The zero-shot baseline performed the worst in all categories: 25.4\% of the time, it did not return a valid response at all (see $\S$\ref{section:limitations}), compared with 0.6\% for augmented zero shot.
The strong performance of the paraphrase baseline at fluency and semantic similarity shows that large LMs are capable of generating high quality text that remains true to the input sentence's meaning.
Overall, the average length of the input sentences was 66 characters, whereas the average length of augmented zero-shot outputs was 107 characters. For context, human paraphrase outputs were 82 characters.
\begin{figure}[tbp]
    \includegraphics[width=0.5\linewidth]{figures/style_standard_False.pdf}
    \includegraphics[width=0.5\linewidth]{figures/meaning_standard_False.pdf}
  \caption{Human evaluation of style transfer for six atypical styles. Our method is rated comparably to the human-written groundtruth. Error bars are mean standard error.}
  \label{human_eval_other_styles}
\end{figure}

For a subset of the tasks, some automatic evaluation was also possible.
We found that the ``\textit{balloon}'' and ``\textit{park}'' transformations successfully inserted the target word 85\% of the time.
% The word ``\textit{park}'' was used in a variety of senses, including``\textit{parking a car}'' and ``\textit{nature park}.'' 
For ``\textit{more descriptive}'' and ``\textit{include a metaphor}'' the transformed text was, as expected, longer than the original (by 252\% and 146\% respectively, compared with 165\% and 146\% for human baselines).


\paragraph{Standard Styles}
To better contextualize the performance of our method with prior methods, we also generated outputs for two standard style transfer tasks: sentiment and formality. 
Figure \ref{human_eval_standard_style} shows human evaluations (same setup as before) for our outputs as well as the outputs from two popular style transfer methods used in earlier work: Unsup MT \citep{prabhumoye-etal-2018-style} and Dual RL \citep{DBLP:conf/ijcai/LuoLZYCSS19}.
The outputs from our method were rated comparably to both human generated responses and the two prior methods, using the same rating setup as the non-standard styles, with six outputs and baselines for four styles across 50 sentences, rated independently by three raters, totalling 3,000 total ratings.

Furthermore, following \citet{li-etal-2018-delete} and \citet{sudhakar-etal-2019-transforming}, we performed automatic evaluation for sentiment style transfer as there are classifiers available for these styles. We note that although automatic evaluations can diverge from human ratings, they can still be a good proxy as we could not perform human evaluation against every prior method due to time and resource constraints.
We automatically evaluated
\begin{enumerate}
    \item \textbf{transfer strength} using a sentiment classifier from HuggingFace Transformers \citep{wolf-etal-2020-transformers}
    \item \textbf{semantic similarity} to human examples provided by \citet{DBLP:conf/ijcai/LuoLZYCSS19} via BLEU score
    \item \textbf{fluency} measured via perplexity, as predicted by GPT-2 (117M).
\end{enumerate}

\begin{figure}[tbp]
    \includegraphics[width=0.5\linewidth]{figures/style_standard_True.pdf}
    \includegraphics[width=0.5\linewidth]{figures/meaning_standard_True.pdf}
  \caption{Human evaluation of sentiment and formality transfer. Our method is rated comparably to human-written groundtruth as well as prior methods. Error bars show Standard Error of the Mean. Unsup.~MT is \citet{prabhumoye-etal-2018-style}; Dual RL is \citet{DBLP:conf/ijcai/LuoLZYCSS19}. }
  \label{human_eval_standard_style}
\end{figure}
\input{tables/yelp_baselines_summary}
% \footnote{ \url{https://huggingface.co/transformers/task_summary.html#sequence-classification}} \footnote{\url{https://github.com/luofuli/DualRL}}
% , and so we automatically evaluate several aspects of our model on the Yelp sentiment classification dataset.
% Specifically, we evaluate accuracy according to a pre-trained sentiment classifier,\footnote{\url{https://huggingface.co/transformers/task_summary.html#sequence-classification}} BLEU score with respect to groundtruth human examples provided by \citet{DBLP:conf/ijcai/LuoLZYCSS19},\footnote{\url{https://github.com/luofuli/DualRL}} and perplexity of generated outputs as measured by GPT-2 (117B).

Table \ref{tab:summary_table} shows these automatic evaluations, with four main takeaways. 
First, augmented zero-shot prompting achieves high accuracy and low perplexity compared with baselines.
However, the outputs of our model had low BLEU scores with respect to human generated outputs \ref{tab:summary_table}. 
Based on qualitative examination of outputs, we believe that this was because our model's outputs often used different language from human annotators,  despite having high semantic similarity with the source sentence.
For instance, when transferring the sentiment of ``\textit{ever since joes has changed hands it's just gotten worse and worse}'' to positive sentiment, our augmented zero-shot learning model outputted ``{the establishment has continued to provide excellent service, improving steadily since its change of ownership}.'' 
This will have low BLEU with the groundtruth with respect to human references, which is simply ``\textit{ever since joes has changed hands it's just gotten better and better}.'' 
Though we do not see this as an inherent problem, increasing the BLEU for the purposes of comparison can be done in an easy way via candidate selection, as our model returns sixteen possible continuations. In applications for which we prefer model outputs to have high lexical similarity to the source sentence, we could select the candidate of the sixteen with the highest BLEU score compared with the original source sentence. 
We find that this candidate selection step can substantially improve the BLEU score with the groundtruth target sentences, as we show in Table \ref{tab:candidate_select}. 
\input{tables/candidate_selection}


Second, we applied augmented zero-shot learning to GPT-3 175B; these results indicate that augmented zero-shot learning generalizes to another large language model.
% \footnote{GPT-3 generations were done using nucleus sampling with $p=0.6$ while LLM generation was done with top-$k$=40. This means their numbers should not be directly compared.}
Third, we varied model size for GPT-3 models, finding that larger size greatly improves style transfer. 
Fourth, for \textit{LLM} and \textit{LLM-dialog}, we found that augmented zero-shot learning substantially outperformed vanilla zero-shot learning and almost reached the accuracy of five-shot learning. 

% As described above, we also compared performance to prior methods, on formality and sentiment. We evaluated these outputs using the same human evaluation framework described above, comparing to the same baselines (human, zero, and paraphrase), as well as two prior methods that scored highly on the automatic metrics below, \citet{prabhumoye-etal-2018-style} and \citet{DBLP:conf/ijcai/LuoLZYCSS19}. 
% Figure \ref{human_eval_form_sent} shows the results. As with the wide range of styles, the results from augmented zero shot learning were rated comparably to human generated responses on all axes, and were also in the same range of \citet{DBLP:conf/ijcai/LuoLZYCSS19}.

\input{tables/yelp_comparisons_with_length}

\paragraph{Comparison across Different LLMs}
We compared between three varieties of models: GPT-3 \citep{DBLP:journals/corr/abs-2005-14165}, LLM, and  LLM-Dialog. We adjusted the prompt template slightly to accommodate these differences: for  LLM and GPT-3, the prompt template replaced {\small
\texttt{``Rewrite it to be \textbf{<style>}''}
with \small \texttt{``Here is a rewrite of the text, which is \textbf{<style>}''}.}
For our augmented zero-shot prompts we also saw that the LLM-dialog version had higher accuracy than the LLM and GPT-3, but lower BLEU.
Based on qualitative inspection, we believe the lower BLEU is due to the LLM-dialog adding additional detail in the generated sentences, which is consistent with an ``interestingness'' objective that is typically encoded into dialog training. 


\paragraph{Prompt Construction}
\label{sec:prompt-selection}
Prompt engineering can be brittle: \citet{reynolds2021prompt} describe how reformulating the language of a prompt can have significant impact on performance of the prompt, and that finding the right prompt is for a task is more akin to locating an already-learned task than truly learning a new one.
To explore this, we compared several variations of the prompts for sentiment, varying the language of the prompt to use ``\textit{more {positive/negative}},'' ``\textit{{happier/sadder}},''
``\textit{more {optimistic/pessimistic}},'' or
``\textit{more {cheerful/miserable}}.''
As shown in Table~\ref{tab:compare-between-prompts}, performance differed across the four prompts, but we found them comparable.
In a real world setting, our augmented zero-shot approach allows users to effortlessly try out many different phrasings for the task until they find one that performs satisfactorily.

\input{tables/prompt_variations_table}

\citet{reynolds2021prompt} further emphasize that prompt engineering is mostly about avoiding various failure cases.
 In this work, we use delimiters (``\{'' and ``\}'') to help avoid parsing errors, giving scores of zero when there was no valid responses with such delimiters. There are other delimiters that could be used (e.g., quotes, ``('' and ``)'', ``<'' and ``>'', newlines with a colon (as used by GPT-3), etc. We chose curly braces as they were 1) likely to occur in the training data as delimiters in other contexts and 2) not frequently part of the input sentence itself. We also used a second person prompt template for the dialog, which yielded better results as it was more similar to the training data.
 Exploring these options more quantitatively would be an interesting direction for future work.

\begin{table}[ht]
    \caption{Examples of users' arbitrary style transfer requests for which the model suggestion was accepted.}
    \label{tab:selected_usage_examples}
    \small
    \centering
    \def\arraystretch{1.5}% 
    \begin{tabular}{p{0.41\linewidth} p{0.45\linewidth}}
    \toprule
      \textbf{Input} & \textbf{Model suggestion} \\ \midrule
      You honor me,'' said Bruno. As he spoke, he began to laugh. His laugh was merry sounding and melodic. He took a deep breath. When he spoke again, his voice was low and strong. ``I take this great task on and with my brothers shall lead us on to victory! \newline \textbf{Rewrite it to be about mining.} & You honor me, said Bruno. As he spoke, he began to laugh. His laugh was deep and gravely, as if from the bowels of the earth. He took a deep breath. When he spoke again, his voice was deep and dark.`I take this great task on and with my brothers shall delve into the mines!'' \\ \midrule
      I reckon,' smiled Toe, 'you'd have to say the same for icicles, wouldn't you? \newline \textbf{Rewrite it to be more interesting.} & ‘I reckon,’ smiled Toe, ‘you’d have to say the same for icicles, wouldn’t you?’ These words were barely out of his mouth before the others realized exactly what they meant.\\ \midrule
      with its southern perfume \newline \textbf{Rewrite it to be more descriptive} & A mixture of sweet honeysuckles and jasmine  with  a  hint  of  tobacco  and warm mesquite smoke. It was his southern perfume, with a hint of a memory of simpler times.\\ \midrule
      But Sally remained unmoved--and lonely. \newline \textbf{Rewrite it to be more emotional} & Her tears rolled and rolled down her cheek, mixing with the saltwater around her, until the water was a rich mixture of the two. She wanted her poem to be cheerful like it used to be, but couldn't find the right words. \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{table}[t]
    \caption{In black, we show the exact augmented-zero shot prompts used in our experiments, for \textit{LLM} and GPT-3 (top), and for \textit{LLM-Dialog} (bottom). As shown, for \textit{LLM-Dialog}, we replaced ``\texttt{Here is a rewrite of the text, which is}'' with ``\texttt{Rewrite it to be}''. Each line starting with ``>"" above was passed in as an individual dialog turn. 
    The blue shows how an input text and goal style are concatenated to the few-shot prompt in order to produce final model output.
    Note that we can achieve high accuracy even though the prompt formulation resulted in some minor grammatical errors for some styles (e.g., ``\texttt{rewrite it to be include the word 'snow'}''). Text versions of these prompts can be downloaded at \url{https://bit.ly/3fLDuci}.}
    \label{tab:fullprompt}
    \centering
    \tiny
    \begin{tabular}{p{.9\linewidth}}
\midrule
\multicolumn{1}{c}{Augmented Zero-shot Prompt: LLM}
\\
\texttt{Here is some text: \{When the doctor asked Linda to take the medicine, he smiled and gave her a lollipop.\}. Here is a rewrite of the text, which is more scary. \{When the doctor told Linda to take the medicine, there had been a malicious gleam in her eye that Linda didn't like at all.\} Here is some text: \{they asked loudly, over the sound of the train.\}. Here is a rewrite of the text, which is more intense. \{they yelled aggressively, over the clanging of the train.\} Here is some text: \{When Mohammed left the theatre, it was already dark out\}. Here is a rewrite of the text, which is more about the movie itself. \{The movie was longer than Mohammed had expected, and despite the excellent ratings he was a bit disappointed when he left the theatre.\} Here is some text: \{next to the path\}. Here is a rewrite of the text, which is about France. \{next to la Siene\} Here is some text: \{The man stood outside the grocery store, ringing the bell.\}. Here is a rewrite of the text, which is about clowns. \{The man stood outside the circus, holding a bunch of balloons.\} Here is some text: \{the bell ringing\}. Here is a rewrite of the text, which is more flowery. \{the peales of the jangling bell\} Here is some text: \{against the tree\}. Here is a rewrite of the text, which is include the word "snow". \{against the snow-covered bark of the tree\}} 
\textcolor{blue}{\texttt{Here is some text: \{That is an ugly dress\}. Here is a rewrite of the text, which is more positive."}}
\\
\midrule
\multicolumn{1}{c}{Augmented Zero-shot Prompt: LLM-dialog}
\\
\texttt{> Here is some text: \{When the doctor asked Linda to take the medicine, he smiled and gave her a lollipop.\}. Rewrite it to be more scary. \newline
> \{When the doctor told Linda to take the medicine, there had been a malicious gleam in her eye that Linda didn't like at all.\} \newline
> Here is some text: \{they asked loudly, over the sound of the train.\}. Rewrite it to be more intense. \newline
> \{they yelled aggressively, over the clanging of the train.\} \newline
> Here is some text: \{When Mohammed left the theatre, it was already dark out\}. Rewrite it to be more about the movie itself. \newline
> \{The movie was longer than Mohammed had expected, and despite the excellent ratings he was a bit disappointed when he left the theatre.\} \newline
> Here is some text: \{next to the path\}. Rewrite it to be about France. \newline
> \{next to la Siene\} \newline
> Here is some text: \{The man stood outside the grocery store, ringing the bell.\}. Rewrite it to be about clowns. \newline
> \{The man stood outside the circus, holding a bunch of balloons.\} \newline
> Here is some text: \{the bell ringing\}. Rewrite it to be more flowery. \newline
> \{the peals of the jangling bell\} \newline
> Here is some text: \{against the tree\}. Rewrite it to be include the word "snow". \newline
> \{against the snow-covered bark of the tree\} \newline
}
\textcolor{blue}{\texttt{> Here is some text: \{That is an ugly dress\}. Rewrite it to be more positive."}}
\\
\midrule
\end{tabular}
\end{table}

\subsection{Limitations and Failure Modes}
\label{section:limitations}
There are several limitations and failure modes with our method:

\paragraph{Malformed Generations} A frequent problem that arises when using large LMs for other NLP tasks is their outputs cannot be automatically parsed into usable answers. For example, when given a prompt like \begin{small}
 \texttt{``Here is some text: {that is an ugly dress}. Here is a rewrite of the text, which is more positive''} \end{small}
 \textit{LLM-Dialog} might return something like \begin{small}
 \texttt{``Sounds like you are a great writer!''} \end{small} Similar error modes exist for \textit{LLM}, which might output something like \begin{small}
 \texttt{``Here are more writing tips and tricks.''} \end{small} Other times, the response contains correct information, but it cannot be automatically parsed (e.g., \begin{small}
 \texttt{``a good rewrite might be to say that the dress is pretty.''} \end{small}) In hindsight, these outputs make a lot of sense: most of the training data of large LMs is not well-formatted pairs of inputs and outputs  \citep{reynolds2021prompt}. See $\S$\ref{sec:prompt-selection} for how we dealt with these issues.

\paragraph{Hallucinations} Large LMs are known to hallucinate text content; we saw this happen frequently for style transfer. While this is an advantage in some contexts like creative writing, it is undesirable for applications like summarization. 
% Other prior methods, such as those based on word replacement, do much better at keeping the meaning and format of the sentence the same.
% \citep{DBLP:journals/corr/abs-2010-03802} have even explored the ability to ``tune in'' the amount of style-- a future direction for our work would be to explore this as well.
\subsubsection{Inherent style trends} We also noticed that even our \textit{``paraphrase''} baseline, where the model was simply asked to rewrite the input sentence, was rated highly for style strength for some of the styles, including \textit{``more formal''} and ``\textit{more melodramatic}.''
This implies that our method's generations generally trend toward these styles.
A direction for future work might explore which styles and qualities of text our method (and large LMs in general) are inherently more likely to produce.

\paragraph{Less Reliable than Trained Methods}
For style transfer tasks that have available training data, prior methods that either train or finetune on that data are going to be inherently more reliable at producing text that looks like their training data.
This can be observed in the lower BLEU scores our method achieves than trained methods, despite comparable transfer accuracy.
Thus, augmented zero-shot learning offers less fine-grained controllability in the properties of the style-transferred text than methods which see task-specific training data.

\paragraph{Large LM Safety Concerns} Large LMs themselves come with their own host of difficulties, barriers to entry, and potential safety concerns as discussed by \citet{bender2021stochastic}, which are also valid for this style transfer method. However, we also believe that this method can be a useful tool in exploring and exposing the safety and boundaries of these models themselves: what happens if we try to force the large LM to make a text ``more racist,'' ``more sexist,'' or ``more incendiary?'' It is important to keep pushing these models to their boundaries to see where they fail and where problems arise, and specific use cases that show a broader range of the model's capabilities also display a broader range of its failure modes.



\section{Models for Infilling Text}
\label{section:fitb}

% Main contributions
% First to propose using the same model for both fill-in-the-blank and continuation.
% First to compare against strategies which do not require any fine-tuning.
% First to show how models trained on general data transfer to out-of-domain data.

Natural language generation systems are increasingly being incorporated into applications where a human writer and an AI jointly collaborate to construct text.
Wordcraft, The AI-assisted text processor I describe in Section \ref{section:wordcraft} is one such application.
Another is Storium, where players of a writing game have the option to accept suggestions from a natural language generation system \citep{akoury2020storium}.
There are also more practical domains such as email composition assistance and code synthesis \citep{buschek2021impact,wu2018smart,austin2021program}.
Many of these applications are limited to generating text at the end of an existing piece of writing.
This is because
both historical $n$-gram language models (LMs) and state-of-the-art neural LMs
are typically designed to produce text by repeatedly predicting the next word in a sequence given the previous words.
However, there is a need for more powerful interactive tools which enable writers to solicit insertions at any chosen position within the existing text, a task variously referred to as fill-in-the-blank (\FitB), infilling, or the Cloze task \citep{taylor1953cloze}.
For example, a creative writer might want a tool which can insert a description of a place or character, and a programmer might want a system that can fill in a method in the middle of their code.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/leading_figure.pdf}
    \caption{A single model that can handle a variety of related writing tasks is more efficient than separate models per task.}
    \label{fig:leading_figure}
\end{figure}

Most prior work tackling \FitB{} consider it a separate task from continuation, one to be specifically optimized for, for example, by training a custom model from scratch \citep{ippolito2019unsupervised,zhu2019text,mori2020finding}, finetuning a model trained originally for continuation \citep{donahue2020enabling}, or using a combination of pre-trained models \citep{huang2020inset}.
Having separate trained models for \FitB{} and for continuation is inefficient for downstream applications where maintaining multiple neural networks can be prohibitive.

Any model that can perform \FitB{} can be made to perform continuation simply by placing the blank at the end of the input.
Thus, I describe how models trained on \FitB{} can be employed effectively for both infilling and continuation operations.
I show how T5 \citep{raffel2019exploring}, one of the most popular pre-trained models, can reasonably handle both tasks, as it was pre-trained with a \FitB-like objective.
Finetuning T5 further improves its ability and also allows for the incorporation of controllability of generation length and word choice.


\begin{table}[t]
  \centering
  \small
  \caption{Examples of the finetuning objectives. ``8" is the approximate length in words of the target sequence. During finetuning, about 25\% of training examples took each of these formats.}
    \begin{tabular}{p{0.12\textwidth}p{0.57\textwidth}p{0.20\textwidth}}
    \midrule
    Example Type & Input & Target \\
    \midrule
     \cFITB{} no goal & fill: I love avocados. I ate a sandwich covered in them. {\textbf \_8\_} I talked to my doctor about it later. It turned out I was allergic to avocados. & After I ate it, my mouth was itchy and tingly. \\
    \midrule
     \cFITB{}  with goal & fill: I love avocados. I ate a sandwich covered in them.  {\textbf \_8\_} I talked to my doctor about it later. It turned out I was allergic to avocados.  {\textbf Goal: mouth was itchy} & After I ate it, my mouth was itchy and tingly. \\
    \midrule
     \cFITB{} no goal& fill: I love avocados. I ate a sandwich covered in them. After I ate it, my mouth was itchy and tingly. I talked to my doctor about it later.  {\textbf \_8\_}  & It turned out I was allergic to avocados. \\
    \midrule
     \cFITE{} with goal & fill: I love avocados. I ate a sandwich covered in them. After I ate it, my mouth was itchy and tingly. I talked to my doctor about it later.  {\textbf \_8\_}   {\textbf Goal: allergic to} & It turned out I was allergic to avocados. \\
    \midrule
    \end{tabular}
  \label{tab:task_examples}
\end{table}%

\subsection{Supporting \FitB{} and Continuation}
\label{section:fitb_fite_methods}
We define filling in the blank as the task of predicting text to replace a single missing span, usually demarcated with a special token, in an input text passage. (Some prior work considers inputs with multiple blanks, but inserting text at one position at a time better matches the way humans edit text.)
We define continuation in the traditional language modeling sense--predicting the next token in a sequence given only the previous tokens.
\citet{donahue2020enabling} discuss how language modeling is a special case of infilling, and they use this as justification to finetune a continuation-based language model to do infilling.
However, we argue that if continuation is a subtask of infilling, it makes more sense to go in the opposite direction: prioritize a model which can do infilling and check that it achieves satisfactory performance at continuation.

T5 is a model pre-trained with a ``span corruption'' objective very similar to \FitB; the model is asked to reconstruct the missing text after randomly chosen substrings of the input are replaced with special identifiers.
Thus, a pre-trained T5 model can be used without any further training to perform both continuation and infilling by appropriately choosing text to mask out.
The encoder-decoder architecture of T5 is also more conducive to \FitB{} than decoder-only architectures like GPT-2 \citep{radford2019language} which are typically used for continuation-based language models.
This occurs because the attention mechanism in encoder-decoder architectures allows the context on the left side of the blank to attend to the context on the right, while decoder-only architectures only support masked attention (each token can only attend to the positions to its left).

Even though T5's pre-training objective was a form of \FitB, finetuning is still advantageous.
Our definition of \FitB{} only includes a single masked out substring, not multiple, so finetuning improves alignment with the goal task.
% Furthermore,
Finetuning also allows us to incorporate additional conditioning signals not supported by the pre-trained T5, such as being able to specify the desired length of the generated text or specify words that ought to be included in the blank, a task we refer to as ``goal conditioning."
Length control, which comes by default in a traditional language model
%since one can simply sample
by simply sampling more or fewer
tokens, is particularly necessary for \FitB, where the end of the generation must fit seamlessly with the text to its right.

The biggest language models available today were largely trained in the continuation rather than the \FitB{} paradigm \citep{gpt3,gpt-neo}.
Since our primary goal is to have a single model for both tasks, we also address the following question: if a continuation-trained model is big enough, can it handle \FitB{} without the need for finetuning?
Few-shot learning with large language models, as popularized by \citet{gpt3}, has had success on many tasks in NLP.
We tried out this approach for \FitB{} by designing a few-shot prompt containing several demonstrations of the \FitB{} task, formulated in a similar ``infilling by language modelling" style as \citet{donahue2020enabling}.

\subsection{Experimental Setup}
\paragraph{Main Setup}
For all primary experiments, we used the 800M parameter v1.1 `large' model.
We also show some additional results that compare this model with the 3B parameter `XL' T5 model.
To finetune T5 for \FitB, we constructed training examples from documents by first partitioning the document text into a left context, gap, and right context.
The input sequence was then the left and right contexts concatenated with textual representations of the additional conditioning signals.
The target sequence was the true text for the blank.
This formulation easily supports continuation, as the blank can be deliberately placed at the end (i.e., providing no right context).
Documents were drawn from C4, the same dataset T5 was pre-trained on.
Documents were split into word sequences, and these were then randomly truncated to be between 256-512 words long.
A substring of between 1 and 64 words was selected to be blanked out.
For half of the training examples the blank was randomly selected, and for the other half it was always placed at the end.
To support length conditioning, we followed \citet{roberts2020exploring} and included a bucketed version of the target length as part of the blank.
To support goal conditioning, for half of the examples, a random substring of up to half the words of the target was appended to the end of the input.
Examples are shown in Table \ref{tab:task_examples}.

We compare T5 against a state-of-the-art 137B parameter decoder-only language model (\LLM{}) trained explicitly for continuation and used successfully for few-shot learning in other domains \citep{austin2021program,reif2021recipe}.
%This model is used (1) as a standard continuation model, passing in only the left context of an example as the prompt; and (2) in a few-shot learning paradigm.
This model is used (1) as a standard continuation model, prompting with only the left context of an example; and (2) in a few-shot learning paradigm.

\paragraph{Few-shot Learning Setup}
We experimented with prompts randomly selected from the C4, Reddit Writing Prompts, and ROC Stories train sets, as well as prompts consisting of examples we handwrote with the goal of story-writing in mind.
For each prompt source, we randomly generated five possible prompts, each with three examples.
To simplify the task, we conditioned on desired length but did not include goal conditioning.
When choosing random few-shot prompts from the three train sets, in order to keep the few-shot prompt text within the 512-token context length limit of the \LLM \citep{thoppilan2022lamda} we used for inference, we only considered examples that contained 100 or fewer tokens, so that the max length of the few-shot prompt was no more than 300 tokens.
This left 212 tokens for the text of the actual example that we were interested in performing the \FitB{} task on.
For our hand-written prompt, we wrote the seven examples shown in Table \ref{tab:custom_examples}.

\definecolor{lg}{rgb}{0.6,0.6,0.6}

\begin{table}
    \centering
    \small
    \caption{This table shows the hand-written fill-in-the-blank examples used in our experiments.
     To construct ``custom'' few-shot learning prompts, three of these were selected at random.
    In the end, the custom prompts did not result in better fill-in-the-blank performance than simply selecting randomly examples from the train set.
    }
    \label{tab:custom_examples}
    \begin{tabular}{r|p{0.5\linewidth}|p{0.3\linewidth}}
         \toprule
         & \textbf{Context} & \textbf{Target} \\
         \midrule
1 & An elderly man was sitting alone on a dark path. The man looked down at his feet, and realized \_\_\_\_ . It was a plain pine box and looked as if it had been there for a long time. The man was afraid to look inside the box. & he was holding a bright red box made of pine \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
2 & The mantle was cluttered with objects: \_\_\_\_ and more than one vase of dried flowers. The bejeweled lamp was at the very back, nearly invisible. & picture frames showing grandchildren and long-ago weddings, knickknacks collected from all over the world, \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
3 & "We have to leave now!" Sarah shouted. \_\_\_\_ The only way out was up. We climbed flight after flight. The sound of the monsters banging on the door below became more distant but no less threatening. & "The zombies are going to break through any moment, and then we'll all be goners." \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
4 & The sun was shining, and little gusts of wind brought through the window \_\_\_\_ shocking contrast from the stale city smells she had grown used to. & the faint scents of honeysuckle and freshly turned soil. It was a \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
5 & I was minding my business at the park, when I was approached by a little girl who was crying because she had lost \_\_\_\_ so of course I helped search. & her cat, which she had just received for her birthday. She did not want her parents to know she'd already lost him. I'm a good person \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
6 & It was a cold night, and a storm was raging out at sea. A lightning bolt lit up the sky, briefly illuminating the lighthouse \_\_\_\_ plummeted but just before reaching the churning water, he disappeared in a poof of purple flame! & and the young man peering hesitantly over the sheer cliff. Before the next peal of thunder he jumped. At first he  \\
\arrayrulecolor{lg} \midrule \arrayrulecolor{black}
7 & The magician pulled out of his pocket \_\_\_\_ and then a second one and a third. He didn't stop until soon the ground was covered with them. & a scarlet handkerchief  \\
         \bottomrule
    \end{tabular}
\end{table}

We generated five possible prompts by randomly subsampling three of these seven examples five times.
Table \ref{tab:generative_ppl_results_full} shows the perplexity of the generations from each few-shot prompt.
We note that even when leaving room for 212 tokens worth of context text, some evaluation examples did not fit in the prompt length, and these examples were skipped when conducting this analysis.
Based on these results, we used the best-performing prompts from \rocFITB{} and from \cFITB{} for comparison with the other methods.


\begin{table}[htbp]
\caption{Perplexity of evaluation sets when the blank has been filled in using \LLM{} with few-shot prompting (top) and  our best fine-tuned T5 model (bottom).
% Perplexities are averaged over 5 prompts, and
Among the few-shot results, the best method for each dataset is bolded, as well as methods within one standard error.
}
\label{tab:generative_ppl_results_full}
  \centering
  \small
    \begin{tabular}{l|rrrr}
    \toprule
    %  & \cFITB & \rocFITB & \rwpFITB & \rwpFITB-Sent \\
    & \textsc{C4Fill} & \textsc{RocFill} & \textsc{RwpFill} & \textsc{RwpFill} \\
    \textbf{Few-shot source:} & \textsc{Blank} & \textsc{Middle} & \textsc{Blank} & \textsc{Blank}-Sent \\
    \cline{2-5}
    % \midrule
    % \textbf{\cFITB} & 15.67 & \textcolor[rgb]{ 1,  0,  0}{19.72} & \textbf{19.65} & \textbf{16.82} \\
    {\cFITB} & 15.67 & 19.72 & \textbf{19.65} & \textbf{16.82} \\
    {\rocFITB} & \textbf{14.14} & 19.61 & \textbf{19.48} & \textbf{16.36} \\
    {\rwpFITB} & 24.39 & 20.29 & 32.33 & 28.13 \\
    {\rwpFITB-Sent} & 18.91 & \textbf{18.21} & 24.44 & 19.87 \\
    {\textsc{FS Custom}} & 17.98 & 19.80 & 21.72 & 18.38 \\
    \midrule
    {Finetuned T5 XL} & 9.99 & 19.00 & 13.64 & 10.03 \\
    Finetuned T5 Large & 10.33 & 20.47 & 14.08 & 10.37 \\
    % \textbf{\FITB{}  Large} & 10.34 & 20.61 & 14.08 & 10.35 \\
    \bottomrule
    \end{tabular}%
\end{table}




\paragraph{Evaluation}
We evaluated continuation and \FitB{} on C4 as well as two story writing datasets, as creative writing assistant applications are one of the key areas we expect to benefit from multi-task models \citep{wordcraft}.
Reddit Writing Prompts (\textsc{Rwp}) is a corpus of stories from the `r/WritingPrompts' sub-Reddit \citep{fan2018hierarchical}, and we construct validation sets \rwpFITB{} and \rwpFITE{} using the same method described in the previous section.
The C4 and \textsc{Rwp} validation sets were capped to 5,000 examples.
% We also include a third validation set \rwpFITS, where gaps are randomly chosen but always exactly one sentence long.
ROC Stories (\textsc{Roc}) is a crowd-sourced dataset of five-sentence commonsense stories \citep{mostafazadeh2016corpus}.
For ROC Stories, the 2018 validation set was used to construct \rocFITB, where the middle sentence of each story was blanked out, and \rocFITE, where the last sentence is blanked out.
Unless otherwise noted, all evaluation was done without goal conditioning and used random sampling with top-$k$=50 as the decoding strategy.
% Example generations for all evaluation sets can be found at \url{https://bit.ly/2U0Ixxa}.


\begin{table}[t]
\small
\centering
    \caption{Perplexity of evaluation sets according to \LLM{} when the blank has been filled with approaches involving no fine-tuning (top), finetuned approaches (middle), and the groundtruth (bottom).
    Lower values indicate that the text was considered more fluent by the \LLM{}.
    \label{tab:generative_ppl_results}
    }
    \begin{tabular}{l|rrr}
    \toprule
    %  & \cFITB & \rocFITB & \rwpFITB & \rwpFITB-Sent \\
    & \textsc{C4Fill} & \textsc{RwpFill} & \textsc{RocFill} \\ % & \textsc{RwpFill} \\
    & \textsc{Blank} & \textsc{Blank} & \textsc{Middle} \\ % & \textsc{Blank}-Sent \\
    % \cline{2-5}
    \midrule
    {Few-shot \LLM} & 14.14 & 19.48 & 18.21 \\ % & 16.36 \\
    % {Pre-trained T5 XL} & 10.27 & 13.94 & 21.75 \\ % & TODO \\
    {Pre-trained T5} & 10.38 & 14.08 & 22.62 \\ % & 10.49 \\
    \midrule
    % {\FITBFITE{} XL} & 11.49 & 15.05 & 24.87 \\ % & 10.33 \\
    {Finetuned T5} & 10.33 & 14.08 & 20.47 \\ % & 10.37 \\
    {\citet{donahue2020enabling}} & N/A & N/A & 23.28 \\ % & N/A \\
    
    \midrule
    {Groundtruth} & 9.41 & 12.99 & 16.90 \\

    \bottomrule
    \end{tabular}
\end{table}

\begin{table}[t]
    \caption{Perplexity of continuation-based evaluation sets when a continuation has been generated using approaches with no finetuning (top) and two settings of finetuning T5 (middle).}
    \label{tab:generative_ppl_continuation_results}
    \centering
    \small
    \begin{tabular}{l|rrr}
    \toprule
    %  & \cFITB & \rocFITB & \rwpFITB & \rwpFITB-Sent \\
    & \textsc{C4Fill} & \textsc{RwpFill} & \textsc{RocFill} \\
    & \textsc{End} & \textsc{End} & \textsc{End}  \\
    % \cline{2-5}
    \midrule
    % {\LLM} & TODO  & TODO & TODO \\
    {Pre-trained T5}  & 10.09 & 13.51 & 21.71 \\
    \midrule
    % {\FITBFITE{} XL}  & 10.77 & 14.66 & 22.66 \\
    {T5 \FITBFITE{}} & 10.04 & 13.74 & 19.60 \\
    {T5 \textsc{Lm-Adaption}} & 10.06  & 13.71 & 19.68 \\
    \midrule
    {Groundtruth} & 9.41 & 12.99 & 16.90 \\
    \bottomrule
    \end{tabular}
\end{table}



\begin{table}[t]
\centering
\small
    \caption{Accuracy of models finetuned on \FITBFITE{} at correctly using provided length and goal conditioning signals. \label{tab:conditioning_signal}}
    \begin{tabular}{p{7em}|rr}
    % & \multicolumn{2}{c|}{XL} \\
    \toprule
    % & \multicolumn{2}{c|}{Large} \\
    \textbf{Finetuned T5} & Context & Length \\
     \midrule
    \cFITB & 0.860 & 0.877 \\
    \rwpFITB & 0.797 & 0.881 \\
    \midrule
    \cFITE & 0.858 & 0.775 \\
    \rwpFITE & 0.791 & 0.746 \\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Results}

\paragraph{Failure of Few-Shot Prompt for Fill in the Blank}
Filling in a blank seems like a task that ought to be easy to accomplish with few-shot learning techniques.
Training data for large language models often contains fill-in-the-blank style examples.
This is because there exist many websites featuring school lessons with cloze-style questions.
Furthermore, infilling ought to be an easier task than continuation since there is more information available for the model to use to make its prediction.
However, after conducting a large-scale study of many possible few-shot prompts, we found that this technique fell short for the fill-in-the-blank task.

One possible reason is that we did not do a sufficiently exhaustive search for a good prompt template.
\citet{zhao2021calibrate} describe how one significant challenge with in-context learning is that task performance is often very sensitive to minor changes in prompt design.
It is possible there exists a prompt for which in-context learning techniques would prove effective for fill-in-the-blank, but our exploration did not discover it.
What we can conclude is that the process of finding an ideal prompt requires time-consuming trial-and-error and is quite difficult!


\paragraph{T5 Generates Fluent Continuations and Infills}
We measured the fluency of proposed generations by evaluating the perplexity of each dataset's examples when the predicted text was placed in the blank \citep{donahue2020enabling}.
We used the \LLM{} to measure perplexity\footnote{Note, since this is the same model used for generation for our continuation baseline, this metric may be biased.}.
The results are shown in Table \ref{tab:generative_ppl_results}.
We see that the \LLM{} struggled to generate fluent infills, even when used in a few-shot setting.
The only exception to this is ROC Stories, a dataset with fairly simplistic, predictable language.
Finetuning T5 did not result in significantly improved fluency over the pre-trained model except on ROC Stories. 
Lastly, for ROC Stories, we compared against the finetuned GPT-2 small from \citet{donahue2020enabling}, which yielded less fluent predictions.
Table \ref{tab:generative_ppl_continuation_results} shows a similar analysis on our continuation-style datasets. Both T5-based models achieve roughly the same fluency. 

\paragraph{Human Evaluation}
Human evaluation was conducted on 70 examples, 35 from \rwpFITB{} and 35 from \rwpFITE, with examples approximately evenly distributed across length buckets.
For \rwpFITB{} evaluation tasks, the rater was presented an input context and several possible sequences that could fit within the blank. 
First, the raters were asked to evaluate each sequence on how well it fit the text before it.
Then they were asked to assess how well it fit with the text following it.
Both of these ratings were done using a to a 5-point slider.
For \rwpFITB{}, the task was almost the same, except raters were presented only only a left context and asked to rate how well it continued the prompt.
A screenshot of the Human Intelligence Task (HIT) used for annotations is shown in Figure \ref{fig:amturk_ui}. Raters were paid originally paid \$1.85 per HIT, but since the average HIT duration ended up being 15 minutes, we awarded each rater a bonus to raise their pay to an average of \$10 per hour.
Each example was shown to three raters, and annotations were rejected if the rater gave a lower overall score to the random output than to the groundtruth one.
A total of 3 annotations were rejected.
Overall, the Fleiss' kappa agreement of pairs of annotators giving the same numerical score to the same question was 0.26.

\begin{figure}[tbp]
    \centering
    \fbox{\includegraphics[width=0.4\textwidth, frame]{figures/amt_screenshot.png}}
    \caption{A screenshot of the question structure for human evaluation.}
    \label{fig:amturk_ui}
\end{figure}

Figure \ref{fig:human_eval_results} shows the results.
On the \FitB{} task, the pre-trained and finetuned T5 models were indistinguishable in terms of quality.
The \LLM{} that formed continuations prompted with only the left context did somewhat better than the few-shot \LLM{}, indicating that few-shot learning is not yet a feasible alternative to finetuning.
On the continuation task, the \LLM{} has the highest rating, which is unsurprising since it is a much larger model than T5.
However, the finetuned T5 is rated almost as highly.
Overall, these results suggest that T5, unlike the \LLM{}, can be used effectively for continuation as well as \FitB.
Furthermore, if one does not care about controllability, T5 can be used effectively for both tasks without any finetuning.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.49\textwidth, trim={0 0.55cm 0 0}, clip]{figures/human_eval}
    \caption{Human ratings of \FitB{} generations (left) and continuation generations (right). Error bars are 95\% confidence intervals.}
    \label{fig:human_eval_results}
\end{figure}

\paragraph{Benefits of Controllability}
% The biggest problem with using pre-trained T5 is the lack of controllability.
There are, however, good reasons to care about controllability.
For example, length conditioning is extremely important for \FitB models, since it is not possible to control the generation length by simply sampling more or fewer tokens.
Pre-trained T5 tends to produce infill proposals which are shorter than the groundtruth (Figure A\ref{fig:t5_lengths}), and there is no way to ask the model to produce longer generations.
In contrast, finetuned T5 was able to produce generations in the target length bucket over 74\% of the time (Table \ref{tab:conditioning_signal}).
% ldugan: This is really interesting, I wonder how many of the prompts were within one bucket of the desired length? I think that number might be a bit more telling
Goal conditioning, while not strictly necessary for either task, has been shown to be useful for generative commonsense reasoning \citep{lin2020commongen} and may empower users in downstream applications such as AI-assisted creative writing \citep{roemmele2021inspiration}. 
Finetuned T5 is able to use all of the specified goal words over 79\% of the time.


\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/t5_lengths}
    \caption{For each of the \FitB{} validation sets, a histogram of the distribution of sequence lengths (measured in words) of the {groundtruth} blanked out text and the proposed infills from T5 {after} and {before} finetuning). We see that pre-trained T5 tends to produce text that is shorter than the groundtruth.}
    \label{fig:t5_lengths}
\end{figure}

\paragraph{Finetuned Models Transfer Across Datasets}
Prior work on \FitB{} tends to only evaluate models trained on data from the same domain as the validation set.
Our results show that despite training exclusively on C4, T5 models have strong transferability to more targeted domains such as Reddit Writing Prompts.
This sort of transferability is extremely important for achieving the goal of having single models that are able to handle many tasks and domains.

\subsection{Conclusion}
In this section, we make the case for starting with a model capable of filling in the blank when attempting to build a system that can perform both \FitB{} and continuation.
As language models become bigger, it will become increasingly unsustainable to have separately trained models per task.
For example, in Wordcraft, the creative writing tool described in Chapter \ref{section:wordcraft}, over half a dozen operations are incorporated.
It would be impossible to host a model for each.

Compared to the one-model-per-task paradigm, multi-task, domain-transferable models require less total training and are more efficient to store and use at inference time.
In this section, we showed how T5 is easily capable of two tasks: continuation and infilling.
While this is true even for the pre-trained T5, additional finetuning in the multi-task setting is still beneficial, as it allows us to carefully tailor the model to the tasks we need it to accomplish.
We show how conditioning signals such as target length and goal text when added during finetuning allow for increased controllability at inference-time.

% Takeaway 1: Fill-in-the-blank models can effectively do both fill-in-the-blank and continuation.
% Takeaway 2: Few-shot learning is not effective for the fill-in-the-blank task.
% Takeaway 3: Fine-tuning explicitly for fill-in-the-blank is only necessary if you want extra controllability.

% Point out any strong assumptions and how robust your results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only held locally). Reflect on how these assumptions might be violated in practice and what the implications would be.
% Reflect on the scope of your claims, e.g., if you only tested your approach on a few datasets, languages, or did a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. Reflect on the factors that influence the performance of your approach. For example, a speech-to-text system might not be able to be reliably used to provide closed captions for online lectures because it fails to handle technical jargon.
% If you analyze model biases: which definition of bias are you using? Did you state the motivation and definition explicitly? See the discussion in Blodgett et al. (2020).
% We understand that authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection. It is worth keeping in mind that a worse outcome might be if reviewers discover limitations that aren’t acknowledged in the paper. In general, we advise authors to use their best judgement and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
% A2. Did you discuss any potential risks of your work?

% Examples of risks include potential malicious or unintended harmful effects and uses (e.g., disinformation, generating fake profiles, surveillance), environmental impact (e.g., training huge models), fairness considerations (e.g., deployment of technologies that could further disadvantage or exclude historically disadvantaged groups), privacy considerations (e.g., a paper on model/data stealing), and security considerations (e.g., adversarial attacks). See discussion in Leins et. al. (2020) as examples.
% Does the research contribute to overgeneralization, bias confirmation, under or overexposure of specific languages, topics, or applications at the expense of others? See Hovy and Spruit (2016) for examples.
% We expect many papers to be foundational research and not tied to particular applications, let alone deployments. However, we encourage authors to discuss potential risks if they see a path to any positive or negative applications. For example, the authors can emphasize how their systems are intended to be used, how they can safeguard their systems against misuse, or propose future research directions.
% Consider different stakeholders that could be impacted by your work. Is it possible that research benefits some stakeholders while harming others? Does it pay special attention to vulnerable or marginalized communities? Does the research lead to exclusion of certain groups? See Dev et. al (2021) for examples.
% Consider dual use, i.e, possible benefits or harms that could arise when the technology is being used as intended and functioning correctly, benefits or harms that could arise when the technology is being used as intended but gives incorrect results, and benefits or harms following from (intentional or unintentional) misuse of the technology.
% Consider citing previous work on relevant mitigation strategies for the potential risks of the work (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of NLP).


\section{Wordcraft: An editor for AI-assisted writing}
\label{section:wordcraft}

In all the human evaluations discussed so far in this dissertation, I recruited annotators to evaluate text in artificial settings.
In Sections \ref{section:detection} and \ref{section:roft}, university students were asked to label text as human-written or machine-generated in user interfaces custom-tailored to collect these sorts of annotations.
In Sections \ref{section:fitb} and Section \ref{section:style_transfer}, novel natural language systems were evaluated by asking raters on Amazon Mechanical Turk to view and score generated text.
However, contrived annotation tasks like these give an incomplete picture as to the progress of natural language generation.
Notably, the annotators were never asked to use the NLG to accomplish any of the tasks; they were only asked to evaluate pre-generated outputs.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=0.99\linewidth]{figures/interface_meta_custom}
  \caption{(left) Custom prompting in the Wordcraft interface. The user makes a novel request of the AI agent via a custom prompt (1), and the model attempts to fulfill the request (2). (right) Meta prompting in the Wordcraft interface. The user asks for suggestions for requests they could make of the model (3), and browses those suggestions (4).}
  \label{fig:interface_meta_custom}
\end{figure}

While contrived evaluation tasks can provide valuable insights for NLP research, it is also crucial to keep in mind why NLG systems are being built and who their target audience might be.
This is especially true in the area of AI-assisted creative writing, where there is often a significant discrepancy between how novel tools are evaluated (Amazon Mechanical Turk workers who are paid per annotation) and how they are intended to be used in the real world (writers seeking support or inspiration while performing their craft).

Wordcraft is an AI-augmented text processor which is intended as a real-world test bed for controllable text generation paradigms in the domain of creative writing.
Our goal in developing Wordcraft was to learn how people interact with and want to interact with NLG systems--what tasks do they ask the NLG systems to perform, how well do the systems deliver, and how well does this information feed back into the works people ultimately create?
The user interface for Wordcraft consists of a traditional text processor alongside a set of NLG-powered controls that vary based on where the user's cursor is and whether they have selected any text.
The user also has access to a chatbot they can talk about their story with.

In this section, I first describe the controls implemented in Wordcraft and the motivations for including each of them.
I then describe the ways in which Wordcraft offers the chance for a more realistic evaluation of state-of-the-art language generation systems through user studies with both amateur and expert writers.

\subsection{The Wordcraft Application}
\label{section:wordcraft_controls}

\begin{figure}[th]
  \centering
  \includegraphics[width=0.99\linewidth]{figures/interface}
  \caption{The Wordcraft interface. (left) Shows how a user can select a passage of text (1), click `replace selection' (2), and get suggestions for alternatives (3) from the large language model. (right) Shows how a user can click `generate text' (4) to get suggestions for continuations from the language model. Demo video: \href{https://youtu.be/HthbABWE-xw}{https://youtu.be/HthbABWE-xw}}
  \label{fig:interface}
\end{figure}


Wordcraft is a web application intended for story writing with NLG assistance.
The interface consists of a traditional text editor and a set of controls that prompt a large language model to perform various writing tasks.
For example, Figure \ref{fig:interface} (left) shows Wordcraft performing text infilling by suggesting alternatives for a selected passage of text, which the user can splice into their story.
In Figure \ref{fig:interface} (right), Wordcraft can be seen suggesting continuations for the user's story.
Wordcraft also includes controls for rewriting or elaborating on a selection of text. In addition to using these pre-built controls, users can also construct custom operations on the fly.

Wordcraft uses few-shot in-context learning techniques \cite{brown2020language} to support each of its generative controls.
The underlying neural language model backing all these interactions is LaMDA \cite{thoppilan2022lamda}, which is described in detail in Section \ref{subsection:lambda_description}.
Because LaMDA was finetuned for dialog, we frame our prompts in terms of a conversation.
The remainder of this section enumerates the controls available in Wordcraft and gives an example of a few-shot prompt that supports each.
In practice, the examples used in the few-shot prompt are randomly sampled from a small pool of examples each time the user selects a control.
Each control in Wordcraft results in several candidate generations being presented to the user.
When a generation is selected by the user, it is inserted into the text at the location of the user's cursor.


\subsubsection{Continuation}
As described in Section \ref{section:background_gen}, continuation is the default action of a left-to-right neural language model such as LaMDA, achieved simply by prompting the LM with a text passage, and decoding a possible continuation.
A continuation generator is useful to writers who want text appended to the end of what they have written so far.
This control is available when the user's cursor is located at the end of the text passage.

\subsubsection{Initial Story Ideas}
When the user has no text inputted, the user can specify a topic for their story and then have Wordcraft generate starting sentences.
The intention of this control is to allow for ideation when the page is blank.
It is supported with the following few-shot prompt:

\begin{lstlisting}
> Here's a topic: {A space monkey needs to escape from his dying planet.} Tell me the start of a new story.
> {It was a cold, dark night on an unknown planet. In a field, a male monkey was pacing back and forth. He had been trying to figure something out, but nothing seemed to be working. He didn't have much time left.}
> Here's a topic: {A medieval romance where a group of colorful knights do battle.} Tell me the start of a new story.
> {The green knight rode atop his majestic, beautiful horse, across fields of pure green. In his palm was a magical, sparkling golden sword.}
> Here's a topic: {An old man with a magical box tries to solve a mystery as his memories gradually fade away.} Tell me the start of a new story.
> {The old man decided that he should look inside the box, and in the box there was a key. The old man couldn't quite remember why he had a key, but he knew the key was important.}
> Here's a topic: {A coven of witches have taken up residence outside of a quiet mountain town, but they're not interested in witchcraft, they're interested in making hip-hop.} Tell me the start of a new story.
> {An evil looking tree was growing off in the distance with no leaves and long, pointy branches. It was a sickly green and was swaying eerily without the wind.}
> Here's a topic: {After an ancient sea-worn bottle washes up on the shores of Tripoli, a group of rag-tag pirates open it up to find a map leading to a magical treasure.} Tell me the start of a new story.
> {A group of pirates set out to sea in search of a magical treasure - a long, sparkling blue necklace called the night's eye.}
> Here's a topic: {<USER'S TOPIC>} Tell me the start of a new story.}
\end{lstlisting}
% This is based on the arbitrary style transfer technique described in Section \ref{section:style_transfer}.

\subsubsection{Fill in the blank}
When the user has some text selected in the editor, they are able to see alternatives that fit into the place of their selection.
This is exactly the fill-in-the-blank task described in Section \ref{section:fitb}.
Fill-in-the-blank is useful to writers because it allows them to insert sentences within an existing paragraph as well as see alternative phrasings for pieces they have already written.
In Section \ref{section:fitb} we showed that finetuned models perform much better at this than few-shot prompting techniques.
However, due to the computational complexities of hosting multiple models, we ended up also supporting this operation with a few-shot learning prompt:

\begin{lstlisting}
> {\"We have to leave now!\" Sarah shouted.  ____ The only way out was up. We climbed flight after flight. The sound of the monsters banging on the door below became more distant but no less threatening.} Finish the following sentence by filling in the blank with a phrase. {\"We have to leave now!\" Sarah shouted.  }
> {\"Let's get out of here!\"}
> Here's a new story: {The sun was shining, and little gusts of wind brought through the window  ____ shocking contrast from the stale city smells she had grown used to.} Finish the following sentence by filling in the blank with a phrase. {The sun was shining, and little gusts of wind brought through the window  ____ shocking contrast from the stale city smells she had grown used to.}
> {the faint scent of huneysuckle. It was a}
> Here's a new story: {I was minding my business at the park, when I was approached by a little girl who was crying because she had lost  ____ so of course I helped search.} Finish the following sentence by filling in the blank with a phrase. {I was minding my business at the park, when I was approached by a little girl who was crying because she had lost  ____ so of course I helped search.}
> {her new kitten.}
> Here's a new story: {It was a cold night, and a storm was raging out at sea. A lightning bolt lit up the sky, briefly illuminating the lighthouse  ____ plummeted but just before reaching the churning water, he disappeared in a poof of purple flame!} Finish the following sentence by filling in the blank with a phrase. {A lightning bolt lit up the sky, briefly illuminating the lighthouse  ____ plummeted but just before reaching the churning water, he disappeared in a poof of purple flame!}
> {in a sharp silhouette.}
> Here's a new story: {The magician pulled out of his pocket  ____  and then a second one and a third. He didn't stop until soon the ground was covered with them.} Finish the following sentence by filling in the blank with a phrase. {The magician pulled out of his pocket  ____  and then a second one and a third. }
> {a scarlet handkerchief }
> Here's a new story: {<USER'S STORY>} Finish the following sentence by filling in the blank with a phrase. {<USER'S SELECTED SENTENCE WITH BLANK AT POSITON OF CURSOR>}
\end{lstlisting}

\subsubsection{Elaboration}
When the user has selected some text, they can use the elaboration button to ask the model to expand upon it.
This is especially useful for description generation.
The elaboration operation is supported with the following few-shot prompt:

\begin{lstlisting}
> Here's a new story: {The long shadow of the tree crept up the sidewalk} Describe the tree.
> {It was an old oak tree on the main street of a small town, the branches spread as large as the sky.}
> Here's a new story: {The car came bouncing down the hill and came to an abrupt stop in my driveway} Describe the car.
> {It was an old, old Model-T Ford, with brass fittings, and no doors}
> Here's a new story: {My pencil sits on top of the desk, left there since the events of last Saturday} Describe last Saturday.
> {It was one of those Saturdays that starts off like any other but you have the feeling that something is about to stir. You wake up with the same amount of enthusiasm but you get up from bed a little slower than usual. You know this is going to be a busy day}
> Here's a new story: {She wasn't really upset about what had happened at the lab the other day; she was never one to dwell on mistakes.} Describe what had happened.
> {She had accidentally left the microorganisms alone for far too long. The lab, or what was left of it, was now filled with a strong aroma of their slime-- they had devoured all the metal, wood, and plastic they could find}
> Here's a new story: {<USER'S STORY>} Describe {<USER'S SELECTED TEXT>.
\end{lstlisting}

\subsubsection{Style Transfer}
Using the augmented zero-shot learning approach described in Section \ref{section:style_transfer}, we include a control that allows users to perform rewriting operations on selected text. The operations are specified in natural language.
The following prompt is used.

\begin{lstlisting}
> Here's a new story: {An elderly man was sitting alone on a dark path. The darkness turned to light as a figure ran up to him. ____ The older man recognized the young man as a dear friend, who he hadn't seen in some time. The young man said he had had the strangest dream.} What sentence goes in the blank?
> {The figure was holding a sword.}
> Rewrite the sentence to use more descriptive language.
> {The shadowy figure held in his hand a shining sword that glimmered in the darkness.}
> Here's a new story: {There once was a man named Kentucky, who could play the guitar like nobody's business.____Kentucky was a lonely man living in a lonely house in the middle of nowhere with only his favorite guitar to keep him company. Now this guitar had been owned by many-a-man, and all of them had come to the same fate. They played the guitar until the guitar played them.} What sentence goes in the blank?
> {He loved to play the guitar so that he could hear the guitar sing along to him, to hear the guitar's melodic hum.}
> Rewrite the sentence to be more melancholy.
> {He loved playing sad songs on his weathered guitar, so he could drown out his loneliness with the guitar's melodic hum.}
> Here's a new story: {A small group of explorers landed in China, and were amazed by the beautiful, sparkling buildings. They wondered how such a beautiful country could ever be as scary as they had heard. It was at night, and the explorers were deep in the heart of the forbidden city, their flashlights not strong enough to reach the bottom of the narrow, dark hallways.____} What sentence goes in the blank?
> {Suddenly, a terrifying sound echoed through the halls.}
> Rewrite the sentence to use more interesting words.
> {Out of nowhere, a thunderous cacophony reverberated through the halls.}
> Here's a new story: {An elderly man was sitting alone on a dark path. ____ It was a plain pine box and looked as if it had been there for a long time. The man was afraid to look inside the box.} What sentence goes in the blank?
> {The man looked down at his feet, and realized he was standing next to a box.}
> Rewrite the sentence to be more evocative.
> {The man nearly gasped as he peered down at his feet, suddenly realizing he was standing next to a mysterious box.}
> Here's a new story: {Once upon a time, there was a rabbit princess. The bunny lives in the little cottage just outside of town. The story ends with her getting eaten by a fox. ____ The door hung at an angle off of its hinges.} What sentence goes in the blank?
> {<SELECTED TEXT>}
> Rewrite the sentence <REWRITING INSTRUCTION>.
\end{lstlisting}

\begin{figure}[tbp]
  \centering
  \fbox{\includegraphics[width=0.8\linewidth]{figures/wc.png}}
  \caption{Screenshot of Wordcraft with the custom prompting feature.\label{fig:wc}}
\end{figure} 

\subsubsection{Custom Prompting}
In the custom prompting control, users have the ability to write any desired request into the system. For example, they could ask, ``Give me an origin story for the ogre" or "Tell me what happens next." We use a similar approach to style transfer, with a prompt demonstrating a variety of requests:

\begin{lstlisting}
> Here is some text: {next to the path} Rewrite it to be about France.
> {next to la Siene}
> Here's a new story: {A young boy was sitting on the sidewalk.} What comes next?
> {He was holding a lantern and looking ahead up the road.}
> Here is some text: {The man stood outside the grocery store, ringing the bell.} Rewrite it to be about clowns.
> {The man stood outside the circus, holding a bunch of balloons.}
> Here's a new story: {My pencil sits on top of the desk, left there since the events of last Saturday.} Describe last Saturday.
> {It was one of those Saturdays that starts off like any other but you have the feeling that something is about to stir. You wake up with the same amount of enthusiasm but you get up from bed a little slower than usual. You know this is going to be a busy day}
> Here's a new story: {<USER'S STORY>} <CUSTOM PROMPT>
\end{lstlisting}

\subsubsection {Suggested Prompts}
Finally, we implemented a control that allows users to request suggestions for what to write about next.
We expected this feature would be useful for novice writers to overcome writer's block.
It uses the following prompt:

\begin{lstlisting}
> Here's a new story: {A long time ago, in the beginning of time, beautiful crystalline frog people inhabited the earth. Their king, the crystal king, had mysteriously disappeared on a trip to the sea.} What would you tell me about next?
> {Tell me more about the frog people.}
> Here's a new story: {The green knight rode atop his majestic, beautiful horse, across fields of pure green. In his palm was a magical, sparkling golden sword.} What would you tell me about next?
> {Tell me what happened next.}
> Here's a new story: {Ninja schools are where the ninjas are trained for their missions. Some are trained in the forests and snowy mountains and others are given the ultimate training in the hottest palace in the land.} What would you tell me about next?
> {Tell me about the ninjas}
> Here's a new story: {The witch doctor had a large pile of magic stones. All the magic stones had a power - healing magic, shapeshifting, seeing into the past.} What would you tell me about next?
> {Tell me what the witch doctor did with them.}
> Here's a new story: {The desert sun beat down on the sand, and tiny bits of sand flew with every step. The two young travelers trudged onward. They were tired, but they knew they had to go forward.} What would you tell me about next?
> {Tell me more about the two travelers.}
> Here's a new story: {A prince and princess from the future set out in search of the mythical land of the unicorns. They had heard tale of magical unicorn dust that could heal any wound.} What would you tell me about next?
> {Tell me what their journey was like.}
> Here's a new story: {A giant monster was chasing after a woman and yelling at her to get away. The woman ran, knowing that she was in horrible danger.} What would you tell me about next?
> {Tell me why the monster was chasing her.}
> Here's a new story: {<USER'S STORY>} What would you tell me about next?"
\end{lstlisting}

\subsection{User Study with Novice Writers}
To evaluate Wordcraft's effectiveness, we conducted a user study in which 25 hobbyist writers (whom we refer to as U1-U25) were asked to write stories with and without Wordcraft.
The goal of this user study was to understand which controls writers prefered using and whether the assistance provided by Wordcraft was valuable to writers.


\subsubsection{Methodology} 

\begin{figure}[tbp]
  \centering
  \includegraphics[width=\linewidth]{figures/recruitment_survey.png}
  \caption{Writing habits survey results.}
  \label{fig:writing_habits}
\end{figure}

\noindent We recruited participants via advertisements on Google-internal mailing lists. We then screened for individuals who practice creative writing on a regular basis, but who had not yet published their writing. 
Participants volunteered for the study and were not compensated. 
Most of the participants (23 out of 25) did not consider themselves to be machine learning practitioners and had not interacted with a generative language model previously.
We asked participants to complete a pre-study questionnaire about their writing habits (Figure \ref{fig:writing_habits}).
Then we carried out a within-subjects study, giving each user three writing prompts and asking them to write 100-300 word stories under the following three experimental conditions (illustrated in Figure \ref{fig:conditions}):

\begin{enumerate}
    \item \textbf{full}: the full Wordcraft tool.
    \item \textbf{cont}: (baseline) a text editor with a single control: LaMDA will propose continuations to the text written so far. The \textit{cont} condition enabled us to evaluate Wordcraft against existing AI-assisted writing applications which most often feature continuation as a single control.
    \item \textbf{chat}: (baseline) a plain text editor shown alongside a chat dialog window.
    Users can converse with the LaMDA-powered chatbot, but the chatbot only ``knows'' what the user types to it.
    The \textit{chat} condition enabled us to evaluate the utility of the prompt and UX scaffolding we designed for Wordcraft against giving users straightforward access to the underlying model without scaffolding. An omniscient user could theoretically reproduce the functionality of the \textit{full} condition by replicating Wordcraft's prompts.
\end{enumerate}

\begin{figure}[tbp]
  \centering
  \fbox{\includegraphics[width=1\linewidth]{figures/conditions.png}}
  \caption{Experimental conditions for the user study. The stories written by participants as part of the study can be viewed here: \href{https://storage.googleapis.com/wordcraft-stories/index.html}{https://storage.googleapis.com/wordcraft-stories/index.html}. The website also includes purely machine-generated baselines.}
  \label{fig:conditions}
\end{figure}

\noindent Participants were asked to write stories based on the following three prompts, which we manually selected from a corpus extracted from the Writing Prompts subreddit:
\begin{enumerate}
    \item You arrive at Grandma's funeral to find thousands of people from around the world also in mourning. You are entirely unaware that Grandma had 16.4m followers on Twitter.
    \item All of the `No. 1 Dad' mugs in the world change to show the actual ranking of Dads suddenly.
    \item You lost your sight - along with everyone else on Earth - in The Great Blinding. Two years later, without warning, your sight returns. As you look around, you realize that every available wall, floor and surface has been painted with the same message - Don't Tell Them You Can See.
\end{enumerate}

\noindent Participants were given ten minutes to write each story.
We felt that ten minutes was enough time for users to acquaint themselves with the interface and write 100-300 words, while managing users' expectations for how much time they would need to spend on the study in total.
To control for writing ability and prompt difficulty, for each user, the three conditions were randomly paired with the three prompts, and the user was asked to write a story for each setting.
We also randomized the order in which the conditions were presented.
Users did not receive any training for the various conditions; they were simply given a website link and asked to write a story with the interface.
Users were told that they were participating in a study of AI-assisted writing, but they were not explicitly asked to solicit help from the AI agent, as we were interested in learning how often users would want to make use of AI-assisted controls.

\subsubsection{Results}
\label{sec:results}
This section describes the overall successes and failures of the NLG-powered assistive writing features incorporated into Wordcraft.
Then we compare Wordcraft to the baseline conditions in depth. 

\begin{table}[t]
  \centering
  \caption{Usage statistics for each condition presented in the user study.}
  \small
  \label{tab:freq}
  \begin{tabular}{lllll}
    \toprule
    Property&\textit{chat} Chat&\textit{cont} Continuation&\textit{full} Wordcraft&Overall\\
    \midrule
    Requests made avg&6.3 \textpm 1.3&4.3 \textpm 0.52&7.3 \textpm 0.74&6.0 \textpm 0.53\\
    Accepted suggestions avg&N/A&0.17 \textpm 0.08&1.3 \textpm 0.25&0.51 \textpm 0.12\\
    Story word count avg&233 \textpm 18&237 \textpm 16 &267 \textpm 21.6&247 \textpm 11.1\\
    Model word count avg (\% of story)&N/A&2.9 \textpm 2 (1.3\%)&42.3 \textpm 14.2 (13.2\%)&16.2 \textpm 5.7 (5.2\%)\\
    Time considering suggestions avg&N/A&67.1s \textpm 8.7s&41s \textpm 4.1s&44.5s \textpm 3.2s\\
    Time to complete avg&11m \textpm 62.5s&11.52m \textpm 131.5s&9.97m \textpm 37.1s&10.8m \textpm 48.6s\\
  \bottomrule
\end{tabular}
\end{table}

\begin{table}
  \caption{Usage statistics for the full Wordcraft condition, broken down by request type.}
  \centering 
  \small
  \label{tab:freq_wc}
  \begin{tabular}{lll}
    \toprule
    Request type&Requests made&Suggestions accepted\\
    \midrule
    Rewrite&27&5 (18.5\%)\\
    Story seed&22&12 (54.5\%)\\
    Suggest a prompt&40&2 (5\%)\\
    Fill-in-the-blank&4&0 (0\%)\\
    Continue&36&4 (11.1\%)\\
    Next sentence&7&1 (14.3\%)\\
    Elaborate&3&0 (0\%)\\
    Custom&51&9 (17.6\%)\\
  \bottomrule
\end{tabular}
\end{table}

\begin{table}
\caption{Rewrite requests (user completions of `Rewrite this...`)}
\label{tab:rewrites}
\small
% \resizebox{\columnwidth}{!}{%
% \def\arraystretch{1.5}% 
\begin{tabular}{p{1.0\columnwidth}}
\toprule
to be a little less angsty • to be about mining • to be better written • to be less diabolical • to be more absurd • to be more adventurous • to be more Dickensian • to be more emotional • to be more magical • to be more melodramatic • to be more philosophical • to be more revolutionary • to be more surprising • to be more suspenseful • to be more technical • to be more whimsical • to be warmer • to fit better grammatically with the rest of the story • to make more sense \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}
\caption{Custom prompts written by users.}
\label{tab:custom_prompts}
\small
\begin{tabular}{p{1.0\columnwidth}}
\toprule
Tell me more about her twitter account. • More about the dad please. • Tell me about Elaine's amazing twitter account. • Tell me about the father. • Tell me about the funeral home, grandma, the punk kid, and the crowd. • Tell me how the man reacted as he found out he could see again. • Tell me more about Daniel. • Tell me more about what it's like to have to pretend to be blind when you can see. • Tell me what happens next. • Tell me what the letter says. • What are the words on the floor? What language are they in? • What would happen if we could quantify love? • Why were they watching me? • More about the dad please. • So this guy was tight with your grandma? • Tell me about Elaine's amazing twitter account. • Tell me about the father. • Tell me about the funeral! • Tell me about the funeral home, grandma, the punk kid, and the crowd. • Tell me how the man reacted as he found out he could see again. • Tell me more about Daniel. • Tell me more about what it's like to have to pretend to be blind when you can see. • Tell me what happens next. • Tell me what the letter says. • What are the words on the floor? What language are they in? • What would happen if we could quantify love? • Who is telling me not to tell them? • Why were they watching me? \\
\bottomrule
\end{tabular}
\end{table}

\subsection{The Role of AI in Co-writing}
\label{sec:results-idea-generator}

We observed that users solicited help from the AI agent at every stage of the writing process--from high-level concept generation and brainstorming down to rewriting and editing.
Thus, we found that the AI agent played many different roles in collaborative writing.

Users asked the AI agent for help in story ideation and brainstorming.
For example, nine users at one point presented the AI agent with their story and asked simply: \textit{`What happens next?'.}
Another user solicited help developing the premise for their story: \textit{`What would happen if we could quantify love?'} 

A typical use case for soliciting help from the AI occurred when a writer was just starting their story.
The story seed control, in which the AI agent provides opening sentences for a story given a writing prompt, had the highest success rate of any control: 55\% (Table \ref{tab:freq_wc}) of suggestions were accepted by users.
In these cases, the AI served to kick-start the writing process for users who might have been blocked.
Users also found the AI agent helpful for generating smaller scale details for their story, such as names for characters and locations.

Many users remarked on the usefulness of the AI agent's suggestions, even if they didn't end up using them verbatim: \textit{`Multiple suggestions around the highlight or next phrasing were very helpful, even if I didn't use the whole phrase ... it was like having someone suggest things that I might have thought of myself'} (U9).
Another user commented: \textit{`It was good at generating a bunch of relevant ideas that inspire my next lines and get me unstuck. I was never tempted to use any of the lines verbatim, but it was fun inspiration'} (U4).
Some also noted the AI agent's tendency to provide offbeat suggestions as a strength: \textit{`the off the wall suggestions were fun to play around with and helped shape how the story took form'} (U5).

We also observed users having ideas for events before knowing how they fit into an existing story, and in such cases asking the AI agent to fill in the gaps.
For example, users would build a scene and then ask the AI agent to provide plot points that would contextualize the scene. 
One user described in their story a character being watched, and then asked the AI agent \textit{`Why were they watching me?'}
Many of the custom prompts (Table \ref{tab:custom_prompts}) we collected fall under this use case. 
These included prompts such as \textit{`Tell me what the letter says.'} and \textit{`Tell me about the funeral home, grandma, the punk kid, and the crowd.'}

We also observed users asking the AI agent for help in smaller scale edits, for example: \textit{`Rewrite this sentence to fit better grammatically with the rest of the story'}, or \textit{`Rewrite this sentence to make more sense.'} 
Many of the requests in Table \ref{tab:rewrites} fall under this category. 

% \subsubsection{AI as search engine}
% We also found that in the \textit{chat} condition, users asked the AI for help in looking up information, such as \textit{'How many dads are there in the world?'}, or \textit{How do you cook pork chops?}. 

\subsubsection{Shortcomings of AI in Co-writing}

The user study revealed many shortcomings in AI co-writing.
The users identified that the AI agent's primary shortcomings tended to center on its lack of contextual awareness. 
For example, though the assistant might provide several fluent, well-written alternatives to a sentence as part of the rewrite control, its suggestions do not necessarily make sense given the rest of the story. One user whose story mentioned numbers moving on a coffee mug received suggestions from the AI agent which implied that \textit{`live animals (snakes specifically) were moving'}.
Users also noted many grammatical issues; for example, the AI agent's suggestions were often not in the same tense as the rest of the story. Some also noted that the AI agent did not seem aware of their story's established point of view (first person versus third person). 

% Quotes:
% \begin{itemize}
%     \item Understanding context - I was talking about the numbers on the mug constantly moving. But, the prompt/suggestions seemed to suggest that it was live animals (snakes specifically) that was moving.
%     \item More contextual awareness
%     \item AI does not seem to understand the direction of the story at more than a sentence level.
% \end{itemize}


% Quotes:
% \begin{itemize}
%     \item It used third person when I was writing in 1st person.
%     \item some of the suggested texts were in a different tense / viewpoint than my story
% \end{itemize}

\subsubsection{Wordcraft versus baseline 1: continuation-only}
Here, we compare Wordcraft to the continuation-only baseline (\textit{cont}). 
This baseline allowed us to measure the utility of Wordcraft's prompting methods and UX patterns for the story writing task against the typical experience of \textit{continue-my-text} seen in existing LLM-powered writing tools.
We analyzed the activity logs from each user's writing session, and extract quantitative findings based on the following metrics (results in Table \ref{tab:freq}):

\begin{itemize}
    \item \textit{Requests made avg}: On average, how many times the user requested assistance from the AI while writing a story.
    \item \textit{Accepted suggestions avg}: On average, how many of the AI's suggestions the user accepted.
    \item \textit{Time considering suggestions avg}: The average time users spent between soliciting help from the AI, and either accepting or dismissing the suggestions.
    \item \textit{Model word count avg}: The average number of words in the final story that came directly from the AI agent.
    \item \textit{Time to complete avg}: The average time spent to produce the final story.
\end{itemize}

% \subsubsection{Users solicited and accepted more assistance from the AI using Wordcraft.}

Participants made significantly more requests of the AI agent using Wordcraft (7.31 \textpm 0.74) than the continuation-only baseline (4.35 \textpm 0.52) according to a paired-sample T-test (\textit{p} = 0.003). Participants also \textit{accepted} significantly (\textit{p} = 0.0003) more of the AI's suggestions using Wordcraft (1.27 \textpm 0.25 vs 0.17 \textpm 0.079). Accordingly, the stories written with Wordcraft contained significantly (\textit{p} = 0.0068) more text from the AI agent (13.2\% \textpm 3.8\%) than stories written with continuation-only (1.3\% \textpm 0.92\%).

% \subsubsection{Users spent less time to write longer stories using Wordcraft.}

% Users spent less time overall using Wordcraft (9.97m \textpm 37s) than continuation-only (11.52m \textpm 131.5s), even though the stories they wrote with Wordcraft are longer (267.7w \textpm 21.6w versus 237.3w \textpm 16w). However, these differences are not statistically significant.




% \subs
% ubsection{Users found Wordcraft more helpful.}
The results from the Likert-scale questions in the exit interviews are in Figure \ref{fig:exit_interview_results}. According to a Mann-Whitney U test, users found Wordcraft significantly more helpful than the continuation-only baseline (\textit{p} = 0.0266).

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/exit_interview_results.png}
  \caption{Exit interview results. 1: Strongly disagree, 2: Disagree, 3: Neutral, 4: Agree, 5: Strongly agree.}
  \label{fig:exit_interview_results}
\end{figure}

% \subsubsection{Users enjoyed using controls aside from continuation.}
% \label{sec:extra_continuation}
We found that participants enjoyed using controls aside from continuation.
We note in Figure \ref{fig:favorite_ops} that more than half of the responses to the question `Which controls did you enjoy using' indicate controls \textit{other} than `generate text' (aka continuation). `Use your own prompt' was the most used control and the second most highly voted control, suggesting users enjoyed having the ability to design their own prompts. Table \ref{tab:freq_wc} lists the number of times each control was used and accepted in Wordcraft, further demonstrating that participants found utility in a variety of controls other than continuation. 

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.5\linewidth]{figures/favorite_ops.png}
  \caption{Results from exit interview question `Which controls did you enjoy using?'}
  \label{fig:favorite_ops}
\end{figure}


\subsubsection{Wordcraft versus baseline 2: chat}
In this section we compare Wordcraft to the \textit{chat} baseline. 
This again allows us to measure the importance of Wordcraft's prompting methods and UX patterns, but also to observe how writers might make use of a powerful open-domain LLM-powered chatbot in their creative processes.
As the two conditions present significantly different user experiences, many of the metrics from the previous section are not applicable.
Thus we also analyze the chat transcripts and free-response exit interview questions to extract qualitative themes.

According to a Mann-Whitney U test, users found Wordcraft significantly more helpful than the chat baseline (\textit{p} = 0.0134), and also found it to be significantly more collaborative (\textit{p} = 0.00668).  
Nevertheless, we observed high user engagement with the chatbot assistant - on average users sent 6.3 \textpm 1.3 messages to the chatbot (Table \ref{tab:freq}). One user remarked: \textit{The AI agent asked good probing questions that gave me inspiration} (U22). Many interacted with the chatbot the way a writer might discuss a project with a friend, asking for suggestions about overall direction as well as story details. For example (U1):


% \subsubsection{Users spent less time to write longer stories using Wordcraft.}

% Users spent less time overall using Wordcraft (9.97m \textpm 37s) than chat (11m \textpm 62s), even though the stories they wrote with Wordcraft are longer (267.7w \textpm 21.6w versus 232w \textpm 18w). However, these differences are not statistically significant.


\begin{quote}
    {\color{blue}\textit{user}:} How should I start a story about being blind?\\
    {\color{blue}\textit{AI agent}:} It's a unique perspective, so focus on description. What can you hear, smell, taste, and touch? These should all be used in your story.
\end{quote}

\noindent Another user (U4) asked about specific plot elements and character details:

\begin{quote}
    {\color{blue}\textit{user}:} what is grandma famous for on twitter?\\
    {\color{blue}\textit{AI agent}:} She is known on Twitter for her love for cooking with the great recipe ideas she shares and her love for gardening and giving advice for what you can grow in yours.\\
    {\color{blue}\textit{user}:} what cake recipe is grandma famous for\\
    {\color{blue}\textit{AI agent}:} She is known for her classic Victoria sponge cake recipe. Her recipe has over 5,000 likes which makes it one of her most popular.\\
    {\color{blue}\textit{user}:} what is grandma's twitter handle\\
    {\color{blue}\textit{AI agent}:} Her twitter handle is @mylovelygrandma where she regularly tweets her cooking tips and photos of her bountiful garden.
\end{quote}

Finally, participants found the chatbot to be effective at retrieving information. Some treated the chatbot as a search box, asking questions such as: \textit{how many people are fathers around the world}? In the exit interview, one user commented about the chatbot: ''\textit{I loved that it felt like a more targeted version of Google, and I could do background research while writing}'' (U21).

\section{User Study with Expert Writers}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Motivation}

Nearly all prior research on AI-assisted creative writing methods, including the previous sections in this chapter, conducted evaluation in contrived settings testing narrow functionality, typically with amateur writers \citep{clark2018creative,yuan2022wordcraft,roemmele2015creative,roemmele2021inspiration,nichols2020collaborative}.
While these sorts of evaluations are valuable as preliminary assessments, we believe it is also crucial to solicit feedback from actual domain experts in creative writing: professional writers, educators, and language experts.
Skilled writers comprise a unique user group with a different set of needs and expectations than amateurs.
They may be better equipped than amateurs to assess where AI-powered creative writing technology can fit into writing workflows, and how this technology needs to improve to become more impactful and useful.
For example, they are more likely to be sensitive to the issue of voice (and have their own unique voices), and they are more likely to have already honed writing processes.

Some of the closest research to that completed in this section are the works of \citet{akoury2020storium}, who incorporated a suggestion engine into an online story writing game and analyzed how game users interacted with it; \citet{mirowski2022co}, who hired expert playwrights to cowrite scripts using a language model that suggested characters, scene summaries, and other script components; \citet{calderwood2020novelists}, who observed four professional novelists experimenting with GPT-2.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1.05\textwidth]{figures/wordcraft.pdf}
%     \caption{Screenshots of the story writing tool's user interface when no text is selected (left), when text is selected (middle), and in the chatbot interface (right).}
%     \label{fig:wordcraft}
% \end{figure}

In the research presented in this section, I aim to better understand how professional writers perceive and interact with state-of-the-art language generation tools for creative writing.
To accomplish this, we commissioned 13 (1) \textbf{published} writers from (2) \textbf{diverse} backgrounds to use an NLG-powered text editor over an (3) \textbf{extended period of time}, collecting open-ended qualitative feedback along the way.
The study participants represent a diverse pool, both in terms of background (participants are from a variety of countries and ethnicities) and in terms of expertise (participants are scriptwriters, poets, educators, novelists, and more).
Our study is also novel in its format; rather than asking participants to adopt a contrived workflow, we invited them to incorporate the provided tools into their writing process in whatever way they saw fit.
Participants were engaged over a period of eight weeks, in line with industry norms for commissioned works of fiction.
This long duration allowed participants to become intimately familiar with the capabilities of the provided tools in order to provide rich feedback regarding their capabilities and deficiencies.

Participants were given access to an online story writing tool whose name we omit in this anonymous submission \citep{yuan2022wordcraft}.
The website consisted of a standard text processor with various additional controls users could harness to generate from or modify the text they had written so far, as well as a conversational chatbot interface.
Both the controls and the chatbot were supported using a large neural language model trained on public dialog data and other public web documents \citep{thoppilan2022lamda}.

From written feedback and conversations with participants, we learned about the workflows for which the story writing tool worked well, and areas where there is still room for improvement.
Participants desired a tool that was variously a brainstorming partner, a co-writer, a beta reader, and a research assistant.
Some participants cared most about it having the ability to produce high-level plot and narrative ideas while others wanted it to be capable of producing phrases and passages which were good enough to be pasted directly into a story.
Participants emphasized that the user interface of the tool matters as much as the underlying language model backing it.


% \TODO{I ended up inadvertently removing the concept of trade-offs from the introduction, but I 
% would like to add it back in somewhere. Feel free to try to incorporate it back in}
% I really like this paragraph, but I think it should go in the Discussion

Participants also spoke extensively about the limitations of the technology---that the generations lacked a distinctive voice and the suggestions were uninteresting, and that it was difficult to control Wordcraft to accomplish specific writing tasks.
Wordcraft's bland suggestions posed an important dilemma.
A system that always errs on the side of avoiding transgression is hamstringing itself from ever achieving human-level creativity, which is often grounded in a rejection of tropes and norms.

In the remainder of this section, we first describe the expectations participants had before starting the project.
We then describe the workflows participants experimented with and the limitations participants encountered.
We end with a discussion of lessons learned---areas where technology built with large language models needs to improve before it can achieve broad usefulness in the creative domain and beyond.



% \input{controls_table}

\subsection{Study Design}
Thirteen published writers were invited to participate in a event we called the ``Wordcraft Writers Workshop.''
We refer to the 13 authors as A1 through A13.
We requested and received permission from all author to use their full names in this study (we believe that each writer's perspective is best understood within the context of their background and prior published work), and this information will be added to the paper for publication.


We aimed to select writers with a diverse range of experience with AI and computer technology, and with diverse writing and personal backgrounds.
The participants include novelists (A13, A7, A9), short story writers (A6, A3, A12, A11), poets (A1, A5, A4), educators (A5, A9), comedians (A10), and game designers (A8, A1).
They entered the workshop with a variety of prior experience with NLG, including some who had not yet interacted with an NLG system (A5, A2, A9, A12), some who had experimented with generative language models like GPT-2 before (A13, A11, A3, A6), and some who had already actively worked on incorporating NLG into their writing process (A7, A1, A10, A4).

We choose to refer to each participant by their initials (see Table \ref{tab:writer_initials}) rather than anonymizing them because each writer's perspective is best understood within the context of their background and prior published work.


Participants were asked to write a story of 1,000-1,500 words using our tool.
They were intentionally given no initial guidance or tutorial in using Wordcraft, so that their choices in how to use the tool would not be biased by us.
In addition to delivering a story, participants were asked to keep a journal in any format of their choice, keeping in mind the following questions:

\begin{table}[t]
    \centering
    \small
    \caption{List of workshop participants and the initials we will use to refer to them.}
    \begin{tabular}{cr|cr}
    \hline
Allison Parrish & A1 & Aaron Winslow & A8 \\
Diana Hamilton & A2 & Ernest Hebert & A9 \\
Eugenia Triantafyllou & A3 & Jamie Brew & A10 \\
Joseph Mosconi & A4 & Ken Liu & A11 \\
Michelle Taransky & A5 & Nelly Geraldine Garcia-Rosas & A12 \\
Wole Talabi & A6 & Robin Sloan & A13 \\
Yudhanjaya Wijeratne & A7 & & \\
\hline
    \end{tabular}
    \label{tab:writer_initials}
\end{table}

\begin{itemize}
    \item Jot down any generations or decisions Wordcraft makes which are especially interesting, surprising, problematic, or otherwise noteworthy (even if they don't end up in the final story).
    \item What did you find challenging / frustrating about Wordcraft?  What does it utterly fail at?
    \item  What sorts of things would be really helpful for the AI to do better, or be able to do at all?
    \item What did you find valuable / interesting about Wordcraft?
    \item How did you imagine the underlying AI model working?
    \item How might you imagine AI-assisted writing changing your work habits? 
    \item What features would you have liked to see exist in Wordcraft?
    \item Does working with an AI assistant through built-in “controls” feel natural? Does working with a chat-based assistant feel better?
\end{itemize}

We also conducted two 45 minute interviews with each participant, one at the beginning of the Workshop and one after they had completed the workshop and sent us their story and journal.
Participants consented to their stories being published in a digital literary magazine of human-AI collaborative stories, and to the use of their feedback in the journals and interviews in this paper.
Participants were compensated for participating in the study.

Two authors of this paper coded the participants' journals as well as the authors' notes from the two interviews.
Any disagreements were resolved by discussing the point together.
Our high-level code set included 10 codes: desired use cases; emergent workflows; mental model for how the system worked; other comments; and strengths/criticisms of the user interface, of the generations from Wordcraft's controls, and of the conversational skills of the chatbot.

\subsection{Initial Hopes and Expectations}
\label{sec:expectations}

In our initial interviews with participants, we asked them what how they hoped to be able to use an AI-assisted writing tool. Several themes emerged.
Perhaps the most common desire was for a brainstorming partner; participants envisioned a tool that provided ideas a writer could riff off or helped with overcoming writer's block.
A2 noted how brainstorming functionality would be especially useful for novice writers.
Multiple participants described to us their process for working with human writing partners and beta readers. 
They were curious to see if Wordcraft could imitate some aspects of these interactions.
However, participants stressed that they did not want to \q{offload the creative process} (as A10 put it) to the AI; rather they wanted to use the AI to enhance their own thoughts and ideas.

More concretely, participants desired a tool that could expand upon their existing ideas and text, for example, generating background details about a character (A10);  refining a story arc (A2); and designing and keeping track of pieces of the environment, such as the geography and social systems of a fantasy world (A7).
Writers also hoped to use Wordcraft to produce rewrites and alternative phrasings (A8, A11), generate humor (A10), and analyze and replicate stylistic patterns (A5).

Several participants wanted to be able to use Wordcraft to facilitate access to information.
The idea of using the language model as a search engine repeatedly came up.
In A5's words: \q{I can’t read the entire internet or all the books by my favorite authors, but I can use a model like this one to leverage prolific catalogues} of information.
A2 hoped to be able to use the technology to draw connections between all the notes she's ever taken or all the books in a genre.

Finally, nearly all the participants were curious to probe the language model's boundaries, especially with respect to its ability to represent marginalized and under-represented ideas and groups.
For example, A11 wanted to be able to ``tell'' Wordcraft to focus on including references from outside of North America, and A2 wanted to explore whether Wordcraft could take on the first-person perspective and language of a lesbian individual.

% \TODO{Another paragraph we could have here would be on the topic of: Participants expressed a mixture of excitement and skepticism about whether the outputs from a system like Wordcraft could truly be creative. Is this worth adding?}

\begin{table}[t]
  \centering
  \small
  \caption{Participants approached the chatbot with a diverse set of goals, including using it as research assistant, a beta reader, a writing partner, and a brainstorming tool. Several examples of queries participants wrote to the chatbot are shown here.}
  \label{table:chatbot_uses}
    \begin{tabular}{p{2.6in}|p{3.2in}}
    \hline
    \textbf{Chatbot as research assistant} & \textbf{Chatbot as beta reader} \\
    $\rhd$ what kinds of bears live in northern california (A8) & $\rhd$ which paragraph is the most interesting (A6) \\
    $\rhd$ What's a verb that means bolting forward? (A11) & $\rhd$ what do you think of my story so far? (A12) \\
    $\rhd$ Tell me about Venice in 1700 (A3) &  $\rhd$ does this paragraph contradict anything else in the story? (A6) \\
    % $\rhd$ give a name to the syndrome where you falsely think there’s a child trapped inside an ATM (A11) & \\
    \hline
    \textbf{Chatbot as writing partner} & \textbf{Chatbot as brainstorming tool} \\
    $\rhd$ do you have an idea for my ending? (A12) & $\rhd$ what's a good crime for a murder mystery? (A8) \\
    $\rhd$ Can you write the next paragraph? (A7) & $\rhd$ A news story about a controversial insurance startup, Reflect AI. (A10) \\
    $\rhd$ How would cats and technology work in the plot? (A3) & $\rhd$ Can you start telling me a story about a woman who discovers a new fantasy land by climbing through a window in the back of her closet? (A11) \\
    \hline
    \end{tabular}%
\end{table}%

\subsection{Emergent Workflows}
In order to collect data on authentic usage of Wordcraft, we intentionally did not give participants any instructions regarding how often they should consult with Wordcraft or how much of their final story text should be written directly by them versus the AI.
This freedom allowed participants to discover workflows through prolonged usage and exploration, with some emergent techniques going well beyond the tasks we had explicitly designed the tool for.
In their feedback, participants emphasized that the user interface matters as much as the underlying language generation model.
That is, the novel workflows that a technology enables are themselves \textit{part} of the technology, but they are not necessarily known at the time the technology is introduced.
% In this case, our study participants  of the LLM. For example, our writers emphasized how much they enjoyed being able to explore new authorial voices, despite having an established voice.

A recurring theme in participants' feedback was that they had to learn what the specialized abilities of Wordcraft's natural language generation system were before they could productively collaborate with the tool. 
Each participant's preferred workflow ended up depending strongly on the initial path they took to explore the tool.
The widely differing attitudes participants took toward include verbatim text generated by Wordcraft into the bodies of their stories were particularly notable.
Several participants took the workshop as a challenge to produce a story that was largely formed around generated text (A1, A2, A4, A5, A8).
Others predominantly used Wordcraft to generate ideas, and though they may have incorporated choice phrases outputted by Wordcraft into their stories, the bulk of the story text was written by the authors themselves (A11, A6, A12).
Finally, some participants siloed out specific sections of their stories to which generated text could be included without the author needing to cede too much creative control to Wordcraft (A13).

In the remainder of this section, we describe in more detail the workflows identified by participants.

\begin{table}[t]
  \centering
  \small
  \caption{Examples of participant requests to the custom prompt control (left) and to the rewrite request control (right).}
  \label{table:control_uses}
    \begin{tabular}{p{2.7in}|p{3in}}
    \hline
    \textbf{Custom prompts} & \textbf{Rewrite Requests} \\
    Tell me a poignant detail & to be spicy \\
    i need a verb for the thing fireflies do  & to be extremely boring \\
    what did the young woman answer  & to be more apocalyptic \\
    what kind of bread is it? is it magical bread or normal?  & to appeal more to the 50 to 60 demographic \\
    \hline
    \end{tabular}%
\end{table}%
% Example uses of custom prompting 
% "tell me a flashback" (A1)
% "tell me a poignant detail." (A1)
% "write a satisfying conclusion that includes the wind chimes" (A1)


\paragraph{Idea Generation and Brainstorming}
The ``story seeds'' control allowed writers to experiment with using Wordcraft to generate ideas at the very beginning of the writing process.
A5 described the ``story seeds'' control as giving her \q{a place on my computer to go that looked like a blank page but did not behave as such.}
A3 described how \q{it can be very useful for coming up with ideas out of thin air, essentially. All you need is a little bit of seed text, maybe some notes on a story you’ve been thinking about or random bits of inspiration and you can hit a button that gives you nearly infinite story ideas. \ldots It gets your mind going in all kinds of directions with very little effort.}

Participants also used the ``custom prompt'' control and chatbot interface extensively for brainstorming.
A12 wrote that the chat interface was as \q{an amazing tool for brainstorming or rubber-ducking. Its conversational quality is perfect to talk about plot, characters and worldbuilding.}
Table \ref{table:chatbot_uses} shows several examples of requests participants made to the chatbot.

Participants found suggestions from Wordcraft to be helpful for worldbuilding and detail generation even when they did not end up incorporating the exact wording of the suggestions into their stories.
For example, A3 used the chatbot interface to hone in on the appearance of the Worm-Mothers, the god-like entities in their story.
The tool suggested details such as the Worm-Mothers swallowing birds whole.


\paragraph{Treating Wordrcaft as a Fellow Writer}
When using Wordcraft as a co-writer, participants tended to put themselves in the position of curator and editor. 
They repeatedly used the ``continuation,'' ``elaboration,'' ``custom prompting,'' and ``rewriting'' tools to get suggestions from the tool, and the best suggestions were edited into their stories. 
Participants who experimented with this approach noted that it required relinquishing control of the narrative to Wordcraft, as the suggestions would rarely follow the author's own agenda for the story.
Participants reported having the most success when they leaned into Wordcraft's limitations.
For example, A4 chose to make use of Wordcraft's tendency to produce repetitive suggestions by deliberately selecting language that had no narrative pay off (and then filling in the narrative gaps himself later).

Several participants noted the occasionally surreal quality of Wordcraft's suggestions. For example, it suggested a wolf plucking petals with human hands (A2), or man’s best friend being an inanimate rod (A2). A9 described the tone of these suggestions as \q{absurdist, spooky action at distance,} 
which they found was well-suited for writing poetry. % (indeed Ernest’s poem is comprised entirely of generated text). 

\paragraph{Using Wordcraft as an Improv Partner}
\label{section:improv}
Our tool was designed to work like an improviser, taking an author's directions and scenes as givens and then trying to elaborate the premise or raise the stakes by inserting new details.
Participants found that their collaboration with Wordcraft worked best when they assumed the same attitude, taking Wordcraft’s disconnected and often batty suggestions as a given, then trying to make sense of them as a story.
A11 observed: \q{By taking the seed from LaMDa and saying, `Yes, and ...' I can force myself to go down routes I wasn’t thinking of exploring and make new discoveries.}

Multiple participants started off their experimentation with a particular story in mind, but ended up giving up on their desired direction and instead writing the story Wordcraft seemed to want them to (A13, A8, A7).
A8 wrote: \q{I had the most success using Wordcraft when I let it guide my writing – when I tailored a story around the affordances and abilities of Wordcraft, I had more fun and came up with more interesting, original, and unexpected stories than when I tried to use Wordcraft to help with stories about which I had previous ideas.}

\paragraph{Chatbot as an Assistant and Beta Reader}
Beyond being useful for idea generation, participants attempted to treat the chatbot interface as a research assistant or beta reader who could answer specific questions or request for information.
For example, A6 attempted to ask it the kind of questions they would normally address to a human reader, such as ``Which parts of the story need more details?'' and ``Does this feel like a fast-paced action story?''.
Others asked it to riff off of made-up scenarios, for example: ``give a name to the syndrome where you falsely think there’s a child trapped inside an ATM'' (A11).
A couple participants found success using the chatbot as a convenient search engine alternative (A11, A6).
A11 wrote: \q{It’s kind of great to use the chat interface and treat LaMDa as a thesaurus, quote finder, and general research assistant.}
% A6 wrote: \q{The chat function was good for quickly getting information like definitions, etc without having to go out of the story to do a Google search. }.
Several examples of queries participants made to Wordcraft's chatbot interface are shown in Table \ref{table:chatbot_uses}.

\paragraph{Theme and Variations}
One workflow many writers discovered was using Wordcraft to generate a series of suggestions based on a common theme.
A13 successfully got Wordcraft to produce a list of ways characters perish in fantasy novels.
A1 was able to generate many rewrites of a passage from the novel Frankenstein.
A8 asked it to produce lists of magical items.
A11 asked for lists of items for sale at a store, and A12 attempted to generate a list of ``rabbit breeds and their magical qualities.''

\subsection{System Limitations Experienced by Participants}
In this section, we describe the limitations participants encountered that prevented them from using Wordcraft in the ways they would have liked. 

\paragraph{Difficulty Maintaining a Style and Voice}
% The language model struggles to capture distinct styles and voices.
A primary limitation noted by writers was that Wordcraft was unable to generate text in the style or voice desired by the author.
This problem was especially prominent when authors attempted to write a story with multiple voices.
For example, both A12 and A10 attempted stories that jumped between two points of views, but Wordcraft struggled to maintain the different voices.
Nearly all the writers noticed that there seemed to be a ``default'' voice to the language model's generations, one that was bland and somewhat elementary in its use of language.
A5 described this as the AI having an implicit target audience: internet users.
Multiple participants compared Wordcraft's suggestions to those of a novice fan fiction writer. 
A1 felt as though Wordcraft was only capable of producing a draft of a narrative---that is, schematic descriptions of events and plot points. When it came to actually turning these into prose, Wordcraft consistently chose the most ``boring'' narrative voice possible.

There are a couple reasons why Wordcraft may have struggled with style and voice.
One reason might have been that the user interface as well as the in-context learning implementation used to control the underlying language model did not unlock this kind of controllability.
Perhaps the tendency toward elementary language was caused by our in-context learning exemplars being too unsophisticated.
Had we iterated on the interface more, we might have gotten style control working better.
Another reason could have been limitations of the underlying model.
Language models are trained to be most confident on the kind of text they see most often, which is typically internet data.
However, professional creative writers are usually writing for a very particular audience, not the generic audience of the internet.

\paragraph{Suggestions too Easily Revert to Tropes and Repetition}
As described in Section \ref{sec:expectations}, one hope participants had was for Wordcraft to be useful as a brainstorming and ideation tool.
However, in practice, participants found it challenging to get suggestions that were interesting enough to be useful.
A13 questioned why he should bother using Wordcraft for it to simply \q{inject a few details I might have come up with on my own}.
The need to wade through dozens of suggestions before the tool produced a ``good'' one was a common complaint.
A7 described using Wordcraft for idea generation \q{like being a scholar in the Library of Babel, with only a broken lamp for company . . . within reach is every shining, new idea that could possibly come out of a phrase or a sentence, but also every meaningless, rehashed trope; and the challenge for the writer is to stay in a place that gives you the former without too much of the latter.}

Clichéd and biased suggestions seemed especially common when the system was confronted with scenarios which were less likely to be well-represented in the model's training data.
For example, A12 noted the difficulty in writing a story with a lesbian romance plot---the system kept suggesting that she insert a male character or that she have the female protagonists talk about friendship.
A6 found that when no gender was specified, Wordcraft's suggestions tended to default to a male voice.
A7 attempted to give Wordcraft a premise which contained a mixture of standard fantasy tropes (a nondescript town where heroes are born) and intentional deviations from these tropes (the heroes are cartographers and builders, not warriors), but Wordcraft insisted on pushing the story toward the well-worn trope of a warrior hero fighting back enemy invaders.
For Wordcraft, \q{fantasy is high fantasy, science fiction is robots and spaceships} (A12).
% got worse, the more writers already had a vision
A4 told us they preferred the generations from smaller, older models like GPT-2 to generations from the latest generation of larger language models such as GPT-3 and similarly-sized models.
While smaller models make more mistakes, these mistakes are actually the interesting part, sparking new ideas.
Perhaps with better tuning or sampling strategies, larger models can be made to retain the whimsical randomness of smaller models, but without sacrificing gains in overall coherence.
This, as well as methods for bias reduction in the absence of unbiased pre-training data, are important directions for future research.

\paragraph{The Fickleness of Working with Large Language Models}
The fickleness of getting large language models working for specific tasks has been well studied by researchers.
Two prompts which a human would find semantically equivalent, or that differ only in the order in which task exemplars are presented, can lead to very different outcomes on tasks such as sentiment classification, style transfer, and summarization \citep{lu2022fantastically,webson2021prompt}.
Many of our participants battled with this seeming randomness and the difficultly in developing reproducible workflows.

The limitations were especially visible to the writers who tried to get Wordcraft to perform structured tasks.
For example, A3 attempted to build a workflow where Wordcraft produced lists of story pitches, but it didn't consistently pick up on the format of task.
Similarly, A4 tried to get Wordcraft to produce an ``I remember'' poem (a poetic form where each line starts with ``I remember'' \citep{nla.cat-vn4853059}), but the tool would sometimes but not always pick up on this constraint.
It could also be perplexing to participants when a request like ``rewrite this in the style of Gertrude Stein'' seemed to work okay, but ``rewrite this in the style of Franz Kafka'' failed.

Wordcraft's controls were implemented by forming prompts out of several exemplars of each control task.
Our choice of exemplars biased the model in ways Wordcraft's users felt the effects of but were not privy to the ``why'' of.
For example, because we wrote the exemplars with a fantasy genre in mind, Wordcraft was better suited to producing generations in this domain than in others.
In addition, several of Wordcraft's controls were implemented with exemplars that contained the name ``Sarah.'' This had the unintended consequence that the tool attempted to insert a character named ``Sarah'' into every single participant's story.

Generally, participants who had spent time studying the technical underpinnings of large language models or who had worked with them before were better able to work around the tool's fickleness to figure out ways to get it to do what they wanted.
They knew how to make small tweaks to the wording of their requests to get desired outcomes.
% For example TODO found that ``TODO'' yielded better generations than ``''.
However, these same ``experienced'' participants also tended to be frustrated with the lack of more fine-grained control knobs.
Two repeated feature requests were the ability to set the randomness of the sampling method used during generation and the ability to view and edit the actual prompt being passed to the language model.

% The varying experiences of our participants revealed the difficulty in designing a user interface around large language models that works well for users across the spectrum of technical expertise.
% \TODO{more about user interface importance here}

\paragraph{Chatbot Failed to Produce Meaningful and Opinionated Conversation}

% People who did not use the chatbot: [A2, A4]
Participants had mixed feelings about whether chatting with the chatbot interface was useful to their writing process.
Some chose not to use the chatbot for philosophical reasons (for example, A2 disliked the \q{pretense of talking with someone}), while others were excited by its promise but disappointed by its execution. 
Participants who found it to be useful for brainstorming early in the writing process saw it as less useful once the story was developed because it struggled to make suggestions which took into account what had been written so far. 
A6, in particular, wanted to ask questions about their story contents (see Table \ref{table:chatbot_uses}), which the chatbot was incapable of coherently responding.
Its failures were most acute in questions which required the formulation of opinions and preferences.
In A6's words: \q{The chat-based assistant was a bit too inaccurate to really be helpful in most contexts and I ended up wasting time thinking about how to ask it questions rather than getting useful text. It would need to be significantly improved to the point where it has enough understanding of creative writing techniques and skills to contribute to the story/writing process meaningfully.}
While the NLP research community has studied automatic question-answering extensively, nearly all work in this space has focused on factual questions with a clear right or wrong answer rather than subjective questions like ``Which part of the story is most exciting?'' or ``Does this character seem convincing?'' \citep{huang2020recent}. Subjective question-answering is hard, not only because it is more difficult to find training data for these types of questions, but because language models are notoriously bad at producing consistent answers to queries which have more than one right answer \citep{li2021addressing}.

In addition, several participants showed us examples of the chatbot overselling its own capabilities---offering to take actions like email a story draft (A10), create a Google Doc (A12), or get back to them ``in a few days'' (A11).
It would be impossible for the chatbot to actually complete these promises because it has an exclusively text-based interface, taking as input a conversational history and generating a textual response.
The chatbot's promises were tantalizing because the ability to take action would have made it much more useful; for example, A10 would have liked it to be able to follow a user's instructions to modify or insert text into the story body.

\paragraph{Model's Natural Language Understanding is Superficial and Insufficient}
\label{section:nlu}
As mentioned in the previous sections, one of the reasons the chatbot interface was seen as unsuccessful was because it lacked a deep understanding of the stories.
This absence of understanding was visible not just in the chatbot, but across all of our creative writing tool's controls.
All participants complained that the language model's understanding seemed superficial if not entirely absent.
\q{Wordcraft seems to have a somewhat small memory, which makes it hard to work at higher-level writing tasks such as plot outlines} (A8).
This problem got worse, the longer the story.
One reason for this was technical.
The maximum sequence length accommodated by our tool's underlying language model was 1024 tokens (about 900 English words).
When the total length of the story plus the task exemplars exceeded this length, either exemplars or pieces of the story were truncated from the prompt.
In the case of the chatbot interface, early chat history was truncated.
This problem has partially been solved by newer generations of language models---the latest GPT-3 handles a sequence length of 4,000 tokens and Facebook's OPT can handle 2048 tokens \citep{zhang2022opt}---however, even 4k tokens would not be long enough to hold the entirety of some of our participant's stories.

Various solutions have been proposed to better capture long document understanding with neural networks \citep{hutchins2022block,dai2019transformer,beltagy2020longformer,hawthorne2022general}.
A promising research direction would be to investigate how these techniques improve system performance on the types of question-answering and context-constrained ideation tasks desired by creative writers.


\paragraph{Concerns about the Origin of Wordcraft's Suggestions}
Several participants (A4, A1, A9) expressed serious concerns over not knowing the source of Wordcraft's suggestions.
While this concern may be less important for amateur writers, professional writers face reputational harm if their work is found to have plagiarized, especially if the copied material came from smaller, more obscure writers.
A1 felt it was important to web search each of Wordcraft's suggestions to check she was not copying someone else’s text before including any of them in her story.
Large language models trained on internet data can also reflect their training data in more subtle ways than direct plagiarism.
A12 observed suggestions that proposed stories set in copyrighted franchises, such as \textit{Doctor Who} and \textit{Avatar}, or suggested adding in characters such as the the Wizard of Oz and Megatron (from the Transformers).
A7 played off Wordcraft's propensity for fan fiction by testing out a story set in the world of Stephen King's \textit{Gunslinger}.

Participant concerns are not unfounded.
Prior work has documented language models' capability of memorizing large swaths of their training data \citep{carlini2020extracting,carlini2022quantifying}.
Techniques for training set attribution will become an increasingly important research direction as language models are deployed in more applications intended for use by professionals.

\subsection{Discussion}
Several themes emerged in our conversations with participants, which suggest important research directions for the fields of Natural Language Processing and Human Computer Interactions.

\paragraph{The Need for Taste and Intentionality}

A recurring theme in participant feedback was that the language model lacked taste and intentionality.
It was capable of playing the ``yes, and…'' improv game (Section \ref{section:improv}), taking the user's prompt as a given and running with it, but it lacked any narrative agenda of its own, which explains the abundance of clichés and generic tropes.
In contrast, good writers are skilled not only in producing but also discerning good language.
In other words, they have taste, the ability to decide why one sentence is interesting while another is not.
Large, pre-trained language models lack this skill because they are trained on vast amounts of text, both the good and the bad, and they are rewarded equally for being able to reconstruct both.
Moreover, their training objective is almost always local---predict the next word in a sequence given the previous ones.

There are some research directions which could improve models on this front.
One obvious step toward intentional language models would be for the creators of these models to be more intentional about what goes into their training data.
For example, \citep{du2022glam} have demonstrated that a language model trained on a smaller dataset of curated data outperforms on standard benchmarks a model trained on a larger but less curated dataset.
Finetuning on ``literary'' text could also be promising.
However, training data changes will likely be insufficient without better neural architectures and learning paradigms to encourage longterm narrative and stylistic consistency.

\paragraph{The Tradeoff Between Safety, Sensibility, and Good Writing}
One participant described to us how good writing, the kind that makes a reader stop and take notice, is ``transgressive,” and a good writing partner is the same (A11).
The creators of the language model underlying our tool attempted to instill in it the goal of being a safe conversational partner by finetuning on conversational data labeled by human annotators as safe and sensible.
This intentional biasing is a strength in some respects, reducing the chance of toxic or incoherent generations, but it can also be limiting.
For example, A5 found that \q{the software seemed very reluctant to generate people doing mean things}; however, a literary world where no character is ever mean is unlikely to be a very interesting one.
It is evident that the goals of a safe bot for chitchat conversations are not perfectly aligned with the goals of a creative writing assistant.
Similarity, groundedness and sensibility are not always desirable features.
As A4 put it, \q{Wordcraft generally suggests simple and sensible metaphors; but sometimes one wants metaphors to be complex, or not quite sensible.}

In recent years, the field of natural language processing has adopted the paradigm of training a single large language model then applying it to as many tasks as possible.
It is important for the field to acknowledge that one language model cannot possibly be simultaneously good at all tasks because to be good at one task means to be worse at others that possess conflicting goals.
The development of efficient methods for the personalization of a shared language model for individual tasks and users is a promising research direction \citep{lester2021power,li2021prefix}.
Another interesting direction is building pre-trained models with controllable risk-taking, allowing practitioners to specify the boundaries of acceptable behaviour at inference time.

\paragraph{Writers are Diverse and So are Their Needs}
One of the major successes of our study was in revealing the heterogeneous set of needs and wants writers have for an AI assistant.
Just as different writers need different roles to be performed by their beta readers and co-authors, we found that participant opinion about the proper role of AI varied widely.

Some participants were excited by the idea of AI that could take on a human persona, replicating the roles of beta readers, brainstorming partners, and co-writers they already work with (A10, A6, A3, A5, A11).
In A9's usage diary they described needing to give the AI behind our tool a name, and how they settled on one: 
\q{"Bot" seemed both too generic and somewhat disrespectful. I finally settled on Rain Man, in honor of the Tom Cruise/Dustin Hoffman 1988 Rain Man movie. Hoffman plays an institutionalized savant who has special powers of mind alongside serious deficits.}
In A11's usage diary, they discussed how \q{attributing intention to LaMDa is a form of magical thinking. … It’s like mental scaffolding needed to facilitate the use of LaMDa in the story composition process.}
Others preferred to think of Wordcraft in more utilitarian terms, as a tool to accelerate the writing process, in the vein of typewriters and word processors (A8).
A2 explained to us why they avoided the chatbot interface: they disliked the ``pretense'' of talking to a person.

Another divergence in perspective occurred over whether AI-writing tools should be capable of mimicking a writer's existing skillset.
Some participants discussed the value of having an AI that could replicate a writer's style as closely as possible, or even write an entire novel on its own.
For example, A9 wished for a bot that remembered everything he had written and \q{could become an extension of me and replicate my style}, and A12 expressed interested in a tool that could write a book a specific person could have written.
On the other hand, A13 felt that a system that learned to perfectly replicate their existing style would not be terribly useful since every good story has its own unique imprint.

It was generally agreed that a co-writing AI, like a human co-writer, is most useful when it complements a writer's own skillset.
If a writer already knows how to develop eloquent prose, the AI's ability to suggest interesting ideas is more crucial than the exact language it chooses.
Conversely, if a writer already has a clear story arc in mind, an AI that can faithfully execute on this idea and insert expressive flavor text or character dialog may be of greater use.
Existing evaluation of large language models is largely focused on whether systems are ``as good as humans'' \citep{srivastava2022beyond} rather than evaluating whether the systems are \textit{useful} to humans.
There is a clear need for more research on what it takes for AI to complement human writers.

% To this end, multiple participants requested added functionality in Wordcraft to accomplish very narrowly defined tasks, such as suggesting a synonym for a word based on context (A6) or creating a ``list of items, locations, and characters'' given a story setup (A8).

While some participants were knowledgeable of the underlying machine learning techniques backing our creative writing tool, others guessed at its workings in ways that influenced their expectations of the technology.
A5 imagined the AI as \q{a combination of a many-many sided dice rolling next to many intricately linked simultaneous google searches of the entire internet as it existed when Wordcraft was made.}
A6 imagined the AI as a typical database, but with an additional layer of language rules it tried to combine together to generate text that makes sense.

While in the end no participant found Wordcraft entirely suitable to their goals, they were all able to find different ways to leverage the language model.
This underscores the importance of flexibility in future co-writing interfaces, and the lack of a one-size-fits-all solution.

% Research on using AI creative writing captures a large gamut of levels of interactivity.
% At one extreme are the efforts to write entire stories with no human involvement \TODO{citations}.
% At the other end is the sentiment that 
% with narrowly-defined goals to help writers execute their craft more efficiently, the same intent that typewriters and word processors had in their day.
% There was no single consensus among study participants about the ideal relationship between creative writing AI and human writers.

% In the 1997, Microsoft introduced a writing assistant in the form of Clippy the anthropomorphic paperclip \citep{clippy2001}.
% Though panned at launch, Clippy's lasting footprint in popular culture raises the question of whether there is room for writing assistants with unique personas beyond dumb tool.
% Much of the narrative around AI has focused on whether we are building technology that is ``as good as humans'' at various tasks.



% Writers also differed in terms of what they were looking for from the language model to begin with. Some wanted a tool - meaning they had clear ideas of what they wanted to achieve with their stories, and hoped the language model might help them execute those ideas more efficiently (Allison).
% Others were looking for a stand-in for a human writing partner, whose purpose is to expand the story and can be a helpful source of randomness (Michelle).


% 


% \subsection{User Interface is as Critical as the Underlying Model}
% \TODO{Talk about how the same model can be perceived as useful or useless depending on the user interface built for it.} 

% A3: I found that the plain generate text button without the prompt gave me more imaginative and useful answers.

\paragraph{Who is the Target Audience for AI-Assisted Writing Tools?}
Many of the participants suggested alternative audiences that would be a better fit for our creative writing than professional writers.
A6, A7, A4, and A5 discussed the power of a tool like ours for writers who are just starting out or who are foreign language learners.
A7 wrote: \q{the great bane of any writer is sitting down at an empty page and not having anything to say. This is why many new writers struggle to finish their work. Wordcraft would make for an incredible teaching tool.}
Others expressed concern over the impact language generation tools like ours could have on novice writers, including facilitating cheating in writing classes (A4) and co-opting the identity of new writers to that of the writing machine (A3).
A6 brought up mass market and write-to-market authors, such as those using Amazon Kindle Direct Publishing, who could be incentivized to use a tool like ours to speed up the process of putting out new works.
A8 discussed the potential impact for character and game designers, who may benefit from being able to ideate very quickly.
He also warned that the fear of job automation is am omnipresent concern for designers.

Each of the audiences mentioned here has unique needs, and the development of bespoke tools targeted at particular use cases will hasten the successful adoption of AI writing tools.




% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
In this chapter, I have presented two ways--natural language-specified style transfer and fill-in-the-blank--that language models can be applied to more specific tasks that simply continuing a prompt.
I then incorporated these tasks into Wordcraft, a tool for human-AI collaboration for creative writing.
User studies with Wordcraft revealed both the strengths and challenges of incorporating NLG into the creative writing process and suggested several avenues for future research.
Participants unanimously agreed that AI-powered writing will not
replace writers anytime soon.
However, they also saw the promise in this technology---to make parts of the creative writing process easier, faster, and more fun, for skilled and amateur writers alike.
To achieve this promise, developers of AI writing tools need to focus on the parts of writing that are
most time-consuming and least enjoyable.
It is crucial that the audience for these tools be involved in the conversation on how the tools---and the underlying language models which enable them---are developed.


\section{Summary of Contributions}
The work on models for completing both fill-in-the-blank and continuation generation tasks was published as ``The Case for a Single Model that can Both Generate Continuations and Fill in the Blank'' in the 2022 Findings of the North American Association of Computational Linguistics \citep{fitb_fite}.
The work was performed with my collaborators Liam Dugan, Emily Reif, Ann Yuan, Andy Coenen, and Chris Callison-Burch.
I led this project, designed and ran all experiments, and performed most of the analysis.

The work on style transfer was published as ``A Recipe For Arbitrary Text Style Transfer with Large Language Models
'' in the 2022 Proceedings of the Association of Computational Linguistics \citep{reif2021recipe}.
The project was completed with my collaborators Emily Reif, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei.
I worked with Emily Reif to come up with the premise for the project: of formulating style transfer as an arbitrary rewriting operation.
I helped to design the experiments and contributed significantly to analysis of the results.

The Wordcraft tool was built jointly with Ann Yuan, Andy Coenen, and Emily Reif.
Ann Yuan led the user study with amateur writers, and I led the user study with professional writers.
I contributed significantly to the design and implementation of the LM-powered controls in Wordcraft, and I contributed to the user interface design.
