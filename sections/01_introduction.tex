\chapter{Introduction} \label{chap:intro}

One of the oldest yet most elusive promises of AI is computers that can converse with humans, not just via rigidly structured templates and programming languages, but in natural language.
In 1950, Alan Turing, one of the fathers of modern computing, framed this goal as an imitation game--computers ought to be able to imitate real human interaction so well that ``an average interrogator will not have more than 70 per cent, chance of making the right identification after five minutes of questioning.''
He expected that by 1950 this game would be solved.

Natural Language Generation (NLG) is a critical component to solving the imitation game.
NLG is the task of writing novel text in a human language such as English. 
Improvements over the last half-decade have led to natural language generation systems which are capable of producing incredibly fluent text.
These systems have been applied to practical domains such as machine translation and text summarization and simplification, but they have also been applied to more fanciful ones, such as story generation, video games development, and tooling for creating writing.

AI-assisted creative writing is a particularly interesting testbed for how far we have come toward achieving Turing's goal.
Unlike in machine translation or summarization, where it is critical that the generated text is factual and stays faithful to the source material, in creative domains, the "hallucinations" and unusual word choices that are pervasive in modern NLG may be beneficial to a creative writer's process.
Indeed, ideation tools, such as decks of cards which suggest writing topics, are commonplace in creative writing circles.
The creative writing domain allows us to evaluate whether NLG systems are useful for accomplishing real writing tasks and whether systems can be easily \textit{controlled} by non-technical users.
This allows us to more holistically evaluate the strengths and limitations of machine-generated text than the narrowly targeted evaluation tasks typically employed in the academic literature.

Before discussing the applications of assisted writing, this thesis first examines two important considerations around the use of modern NLG systems.
Modern NLG relies on neural language models, neural networks trained on billions of words of text in order to represent human language.
Chapter \ref{chap:background} gives an overview of how these systems work. 
Understanding the limitations of these language models and the nature of the text they are capable of generating is crucial to the ultimate use of these systems in real applications.

A significant limitation for creative applications like Wordcraft is the difficulty in generating text that is diverse (containing uncommon and interesting words and phrases) and high quality (as perceived by human readers).
Very often, practitioners choose text generation startegies that err on the side of human-perceived quality at the expense of lexical diversity.
This decision leaves subtle signatures in the generated text which make it easy for automatic classifiers to distinguish it from genuine human-written text.

Chapter \ref{chap:decoding} focuses on this challenge and its ramifications to the detectability of generated text.
The proliferation of machine-generated text, especially when it lacks attribution, is of significant concern to the public, and understanding detectability is also imperative because it gives us a proxy for how far along NLG systems are at fooling humans and whether undesired use of machine-generated text can be mitigated.
In this chapter, I measure the ability of humans as well as automatic systems to detect machine-generated text, and show the connection between detectability and the diversity-quality tradeoff in generated text.

% As tools for generating text become more powerful and easier to use, they could enable nefarious uses such as fabricated product reviews and social media posts.

One difficulty in studying human ability to detect machine-generated text is that it can be very difficult to collect annotations.
Many of the errors NLG systems make are subtle and require closely reading several sentences of text to be able to identify.
Common strategies for soliciting human annotators, such as paying crowd workers a fixed dollar amount per annotation, do not tend to yield useful annotations since annotators are not incentivized to spend the extra time to do a close read.
In order to be able to study human detection ability at scale, we built the Real or Fake Text game (RoFT), a website that gamifies the task of identifying machine-generated text \citep{dugan2020roft}.
The RoFT platform allowed us to collect over 40,000 annotations of whether players could correctly identify when a passage of text transitioned from being human-written to being machine-generated .
Chapter \ref{section:roft} presents a detailed analysis of the factors we found that most impacted detectability. 
 
Of course, machine-generated text is most undetectable when it looks \textit{exactly} like its training data.
Large language models are worryingly capable of memorizing and regurgitating significant amounts of their training data.
For example, GPT-3, a popular model that has already been incorporated into several products, when prompted with the first sentence of \textit{Harry Potter} or \textit{Lord of the Rings} will accurately generate the first several paragraphs of each book.
This behaviour is especially problematic for the domain of AI-assisted creative writing, as writers using tools such as Wordcraft have the expectation that the generations they are being shown are unique and not plagiarized.
Memorization also makes the task of studying the detectability of generated text more challenging.
If an NLG system generates Chapter 1 of \textit{Harry Potter}, should this text be labeled as human-written or machine-generated?
Chapter \ref{chap:memorization} focuses on this question of memorization.
First, we show how performing thorough deduplication of training data results in models that are less likely to exhibit memorization.
Then we conduct experiments showing how observable memorization scales with respect to the number of times a sequence occurs in the training set, the model size, and the length of conditioning prompt \citep{carlini2022quantifying}.

Finally, Chapter \ref{chap:creativity} describes my contributions to the field of AI-assisted creative writing. 
It discusses the importance of introducing controllability into natural language generation systems--providing writers the ability to dictate what kind of text gets generated and decide how it interfaces with what they might have already written.
In particular, we introduce methods for efficiently supporting a fill-in-the-blank paradigm, where a writer can insert text into any position of their current text \citep{fitb_fite}.
We also describe a simple recipe for supporting style-transfer into any user-defined style without the need for costly training data acquisition and test-specific model training.
Both these approaches are incorporated into Wordcraft, an AI-augmented text processor that provides several interfaces for writers to get feedback and suggestions from an NLG system.
In user studies with both amateur and skilled writers, we found Wordcraft to be a valuable assistive tool for creative writing.





\section{Thesis Statement}
In this thesis, I argue that we need to build a deeper understanding of neural network-powered language generation systems before they are safe to deploy these systems widely.
To thwart NLG systems being used in ways that are detrimental to society, it is crucial to understand how machine-generated text differs from the text a human would write given the same writing task.
My research focuses on two such differences: (1) how the word choices made by NLG systems cause generated text to be distinguishable from human-written text, and (2) the tendency of NLG systems to plagiarize verbatim from their training data when asked to produce novel content.
Both of these issues make it difficult to evaluate machine-generated text.
In the first case, the tradeoff between generating high-quality versus generating lexically diverse text makes it challenging to simultaneously optimize for text that is pleasing to human readers and text that is statistically indistinguishable from human-written text.
In the second case, memorization leads to us over-representing the strength of NLG systems by attributing generalization ability to what is actually memorization ability.
To this end, I argue that we should be evaluating NLG systems holistically as part of larger tools meant to \textit{assist} human writers in tasks they wish to accomplish (in addition to evaluating on isolated individual tasks).
I present a case study evaluation of human-AI writing collaboration in the domain of creative writing.

\section{Publications Presented}
The work described in this thesis has been published in several conference papers. In all cases, the work was completed jointly with collaborators at University of Pennsylvania and/or Google Research.
At the end of each chapter section, I include a summary of my primary contributions to the work.

\begin{itemize}
  \item \fullcite{ippolito2019comparison}
  \item \fullcite{ippolito2020automatic}
  \item \fullcite{dugan2020roft}
  \item \fullcite{lee2021deduplicating}
  \item \fullcite{carlini2022quantifying}
  \item \fullcite{reif2021recipe}
  \item \fullcite{wordcraft}
  \item \fullcite{yuan2022wordcraft}
\end{itemize}


% specific limitations and what I tried to prove about them.


% Section \ref{section:div-quality} discusses research that analyzes the inference-time tradeoff between generating interesting and diverse text and generating text that humans perceive as high-quality.
% We show how this tradeoff was present in earlier LSTM-based sequence-to-sequence models and still persists in today's state-of-the-art neural language models.
% The tradeoff exists because of the manner in which nearly all neural networks for language generation are trained.
% These models are trained using a log-likelihood loss to predict a probability distribution over the vocabulary for what the next word should be in a sequence of words.
% Because the log-likelihood loss always assigns some non-zero probability to each word in the vocabulary, the model's predicted probability distributions always have a long tail of low-likelihood words.
% Unfortunately this poses a significant challenge; we do not have good strategies for disambiguating between words which are assigned a low likelihood because they are interesting and surprising, words that are assigned a low-likelihood because they did not occur frequently enough in the training set to be well-modeled, and words which truly are poor choices to continue the text.
% All decoding methods (the algorithms used to sample text from the output probability distributions) make some decision about the extent to which they will choose words in the low-likelihood tail of the distribution.
% On one hand, if one chooses a decoding method which avoids sampling from the tail entirely, humans might prefer the resulting generated text, even though it distributionally no longer looks like what a human what actually write.
% On the other hand, if one chooses a decoding method that occasionally selects unlikely words, there is a greater chance the system will make poor word choices. This does mean though that the system will use uncommon words at a rate more similar to human writers.

% The relative strengths of different NLG systems, especially ones meant to generate text in open-ended domains such as fiction writing or chatbots, cannot be truly assessed without human evaluation.
% This is because automatic evaluation is not sufficient to capture generation quality.
% For example, perplexity on a validation set can give a sense of how well a model represents natural language, but it does not capture perceived differences in quality caused by the quality-diversity tradeoff seen at inference time.
% Similarly, targeted downstream tasks such as common-sense reasoning and question-answering can help answer the question of whether a language model is able to generate factual, non-contradictory text but they do not provide insight into human stylistic preferences or a model's ability to generate entire multi-paragraph passages with narrative coherence.
% In Section \ref{section:human-eval}, two systems are presented which were designed to tackle the challenge of human evaluation.
% In ChatEval (Section \ref{section:chateval}), we propose a system to fairly compare different chitchat chatbots by asking human raters to report which system's output they prefer. With the Real or Fake Text (RoFT) website (Section \ref{section:roft}), we propose evaluating NLG quality through a detection task, where human raters are challenged to figure out when a passage of text transitions from being human-written to being machine-generated.

% The final section of this proposal (Section \ref{section:future}) describes ongoing projects which will complete my thesis.
% I propose to continue the line of work on computer-assisted storytelling by focusing more strongly on how humans interact or want to interact with text generation systems.
% I propose to build user interfaces with many different types of controllability (further detail provided in Section \ref{section:controllability_proposal}), which will make it possible to investigate how useful/enjoyable different controls are for creative writers of different experience levels through user studies.
% Since Human Computer Interaction (HCI) is outside my domain of expertise, I am actively collaborating with HCI researchers at Google on this line of research.
% In addition, to enable better models to be trained in story domains where high-quality datasets tend to be quite small, I propose a method for extracting story-like datasets from massive Common Crawl datasets (Section \ref{section:score_filter_proposal}).

% Insights from our investigations into the diversity-quality tradeoff have led to observation of a related phenomena--since language models are explicitly trained to make text in their training set as likely according to the model as possible, they have a troubling ability to regurgitate phrases copied verbatim from their training data \cite{carlini2020extracting}.
% This tendency may be especially problematic in creative writing applications since authors ought to be made aware if the NLG suggestions they are being provided are simply paraphrases of Shakespeare or Dickens.
% To complete my thesis section on analysis of LM-generated text, I propose conducting a systematic and large-scale study of just how often memorization occurs and whether there exist trends between when text is seen during training and whether that text was memorized by the language models.
% This planned research is discussed in further detail in Section \ref{section:memorization}.

% Lastly, in Section \ref{section:roft_plans}, I propose a largescale human evaluation study using the RoFT system to compare NLG abilities across different subject domains and trained neural networks.
% This study will complement the proposed HCI research on methods of controllability for creative writing purposes.
% While in RoFT all users see and evaluate the same set of pre-computed generations, the controllability project will analyze what generations users choose when they are presented with several candidates custom-tailored to each unique user-specified prompt text and control signals.




% \begin{itemize}
% \item{What problems arise when attempting to use language models for generation in real-world settings?}
% \item{How can neural language models be used to enable creativity}
% \end{itemize}

% The first problem I focus on is the ability to generate text that humans perceive as high quality but has the same diversity of language present in genuine human writing.

% The second problem is on what happens when generated text is \TODO{}. Are humans able to notice when they are reading language model-generated text?

% The third problem is the privacy implications of training on large, barely curated text datasets extracted from the internet.  


% Moreover, the ability to finetune on corpora of in-domain text or to use few-shot learning to influence generation has created a deluge of exciting applications of these models.
% These range from fun applications like machine-generated RPG games\footnote{\url{https://play.aidungeon.io/}} and fake presidential Tweets\footnote{\url{https://faketrump.ai/}} to practical tasks like closed-book Q\&A \cite{roberts2020much} and summarization \cite{zhang2019pegasus,fabbri2020improving}.
% The first half of this thesis explores the capabilities of neural language models to assist humans in real-world writing tasks, with a specific focus on being able to use natural language generation (NLG) systems to aid in the creative process of storytelling and narrative construction.
% However, amid the fast-paced advancements in this field it is vital that research into understanding and evaluating the generative capabilities of large language models keeps pace with their application to new tasks.
% Thus, the second half of this thesis involves analyses to better understand the capabilities and relative strengths of NLG systems.

% While computer-assisted creative writing has long been an interest of NLP researchers \cite{meehan1977tale,klein1973automatic}, it remains a very difficult task for a number of reasons.
% First of all, good stories tend to have coherent narratives that span paragraphs, chapters, and even entire novel series, far beyond the sequence length most neural networks operating on word sequences can naively handle.
% Section \ref{section:sentence_lms} proposes a method for capturing coherence across sentences, rather than across individual words as most standard language models do.
% Second, replacing human story writers with ML is not nearly as interesting a goal as providing tools to assist in the creative writing process.
